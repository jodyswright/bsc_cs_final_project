{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3c4334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files of size:\n",
      "Images: (14190, 281, 362, 1)\n",
      "Labels: (14190,)\n",
      "(11352, 281, 362, 1) (2838, 281, 362, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# pip install tensorflow Version: 2.17.0\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras import models, layers\n",
    "\n",
    "# Version: 3.4.1\n",
    "from tensorflow import keras\n",
    "\n",
    "# use for splitting the test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from scipy import spatial\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for the creation of the cartesian product grid\n",
    "from itertools import product\n",
    "\n",
    "# for the timing of each test\n",
    "import time\n",
    "\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "\n",
    "# the data tools module\n",
    "import data_tools as dt\n",
    "dh = dt.Data_Handling(output_size=5)\n",
    "\n",
    "# set the paths to load the processed data\n",
    "CURRENT_DIR = os.curdir\n",
    "label_path = f'{CURRENT_DIR}/data/mitdb_labels_reduced.npy'\n",
    "data_path = f'{CURRENT_DIR}/data/mitdb_data_reduced.npy'\n",
    "\n",
    "# get the data\n",
    "dh.load_data(label_path=label_path, data_path=data_path)\n",
    "\n",
    "# split into train and test sets\n",
    "dh.split_data(split=0.2)\n",
    "\n",
    "print(dh.X_train.shape, dh.X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3c2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population:\n",
    "    '''\n",
    "    handle population creation of given size, genome length and gene length\n",
    "    \n",
    "    parameters:\n",
    "        max_depth (int) the maximum depth of a genome representing the number of layers\n",
    "    '''\n",
    "    def __init__(self, max_depth=5):\n",
    "        \n",
    "        self.__max_depth = max_depth\n",
    "\n",
    "        self.__global_spec = {\n",
    "            'learning_rate':[0.1, 0.01, 0.001, 0.0001],\n",
    "            'optimizer':['adam', 'sgd'],\n",
    "            'start_size':list(range(8, 33, 8)),\n",
    "            'batch_size':list(range(64, 257, 32))\n",
    "        }\n",
    "        self.__layer_spec = {\n",
    "            # ensure successive layers 1.1 to 2 times that of prev\n",
    "            'filter_size':[i/10 for i in range(11, 20)],\n",
    "            # for future use\n",
    "            'filter_step' :[i for i in range(2, 16)],\n",
    "            'filter_activation': ['relu'],\n",
    "            'dropout_exists': [True, False],\n",
    "            'dropout_rate': [i/10 for i in range(2, 6, 1)],\n",
    "            'max_pool_exists': [True, False],\n",
    "            'max_pool_size' : [2, 3]\n",
    "        }\n",
    "    \n",
    "    def get_genome(self, depth=1):\n",
    "        '''\n",
    "        Creates a genome to include a global gene and at least 1 layer\n",
    "        \n",
    "        Params:\n",
    "            depth (int) the number of layers within the genome\n",
    "\n",
    "        Returns:\n",
    "            genome (array) an array of genes\n",
    "        '''\n",
    "        assert depth >= 1, \"Size must be at least 1\"\n",
    "\n",
    "        # global gene\n",
    "        genome = []\n",
    "        genome.append(self.get_gene(len(self.__global_spec)))\n",
    "        # layer genes\n",
    "        [genome.append(self.get_gene(len(self.__layer_spec))) for g in range(depth)]\n",
    "        \n",
    "        return genome\n",
    "    \n",
    "    \n",
    "    def get_gene(self, size=4):\n",
    "        '''\n",
    "        Creates gene of the given size containing random floats in the interval [0.0, 1.0)\n",
    "        \n",
    "        Params:\n",
    "            size (int) the number of values within the gene\n",
    "        \n",
    "        Returns:\n",
    "            gene (array) a single gene\n",
    "        '''\n",
    "        \n",
    "#         create a random gene of the given size\n",
    "        gene = list(np.random.rand(size))\n",
    "\n",
    "        return list(gene)\n",
    "    \n",
    "    def get_population(self, size=3):\n",
    "        '''\n",
    "        Creates a population of the given size with random length genomes\n",
    "        \n",
    "        Params:\n",
    "            pop_size (int) the number random genomes to return\n",
    "        \n",
    "        Returns:\n",
    "            population (array) an array of genomes\n",
    "        '''\n",
    "        \n",
    "        population = [\n",
    "            self.get_genome(\n",
    "            np.random.randint(1, self.__max_depth + 1)) for i in range(size)\n",
    "        ]\n",
    "\n",
    "        return population\n",
    "    \n",
    "    def map_gene(self, gene, spec):\n",
    "        '''\n",
    "        maps a float value to a discreet parameter value which can be used as a hyperparameter\n",
    "        \n",
    "        Params:\n",
    "            gene (list) a gene consisting of 1 or more float values\n",
    "            spec (dict) the spect to be used within a keras model representing various hyperparameter settings\n",
    "            \n",
    "        Returns:\n",
    "            mapped_gene (dict) mapped values usable in their corresponding hyperparameter\n",
    "        '''\n",
    "        mapped_gene = {}\n",
    "        \n",
    "        for i, (k, v) in enumerate(spec.items()):\n",
    "\n",
    "            map_idx = int(math.floor(gene[i] * len(v)))\n",
    "            mapped_gene[k] = v[map_idx]\n",
    "        \n",
    "        return mapped_gene\n",
    "            \n",
    "    def map_genome(self, genome):\n",
    "        '''\n",
    "        creates a full set of hyper parameter values for a single model\n",
    "        \n",
    "        Params:\n",
    "            genome (list) a set of genes to be mapped\n",
    "        \n",
    "        Returns:\n",
    "            mapped_genomes (dict) a full set of hyperparameters\n",
    "        \n",
    "        '''\n",
    "        mapped_genomes = {}\n",
    "        mapped_genomes['global_params'] = self.map_gene(genome[0], self.__global_spec)\n",
    "        \n",
    "        mapped_genomes['layer_params'] = {\n",
    "            i: self.map_gene(genome[i], self.__layer_spec) \n",
    "         for i in range(1, len(genome))\n",
    "        }\n",
    "        \n",
    "        return mapped_genomes\n",
    "    \n",
    "    def map_population(self, population):\n",
    "        '''\n",
    "        Takes an entire populations genomes and creates a mapped dict for each\n",
    "        \n",
    "        Params:\n",
    "            population (list) a list of genomes \n",
    "            \n",
    "        Returns:\n",
    "            mapped_population (list) the entire population represented as a list of parameter dicts\n",
    "        '''\n",
    "        mapped_population = [self.map_genome(g) for g in population]\n",
    "        \n",
    "        return mapped_population "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53ad8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Constructor:\n",
    "    '''\n",
    "    handles the stages of mapping a genome to the required set of \n",
    "    hyper-parameter values of various types. these are used to build and\n",
    "    compile a training ready model\n",
    "\n",
    "    parameters\n",
    "        shape (tuple) specifies the input shape of the data to be modelled eg (28, 28, 1) \n",
    "        output_size (int) the number of classes to be modelled eg 5\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, shape, output_size):\n",
    "        \n",
    "        self.__shape = shape\n",
    "        self.__output_size = output_size\n",
    "        \n",
    "    def build_model(self, parameters):\n",
    "        '''\n",
    "        builds a keras model of varying depth.\n",
    "        the depth is defined by the length of the layer_params\n",
    "        layers such as dropout and pooling are added if the parameters specifies true\n",
    "        each layer will have at least 1 conv2d and at most conv2d, maxpool, dropout\n",
    "        parameters are defined by the two sets passed in\n",
    "        \n",
    "        parameters:\n",
    "            parameters (dict) set of mapped parameters\n",
    "            \n",
    "        returns:\n",
    "            model (keras.model) a compliled model ready for training\n",
    "        \n",
    "        '''\n",
    "        global_params = parameters['global_params']\n",
    "        layer_params = parameters['layer_params']\n",
    "        # used for the scaling of each filter size\n",
    "        prev_size = global_params['start_size']\n",
    "        # new empty model\n",
    "        model = keras.Sequential()\n",
    "    #     # set the input shape\n",
    "        model.add(keras.Input(shape=self.__shape))\n",
    "        \n",
    "        for i, key in enumerate(layer_params.keys()):\n",
    "            # extract the current layer's parameters to make code more readable\n",
    "            params = layer_params[key]\n",
    "            # calculate the layer size base on the previous size\n",
    "            layer_size = int(params['filter_size'] * prev_size)\n",
    "            \n",
    "            # CONV2D\n",
    "            model.add(\n",
    "                keras.layers.Conv2D(\n",
    "                    filters=layer_size, \n",
    "                    kernel_size=3, \n",
    "                    activation=params['filter_activation']\n",
    "                )\n",
    "            )\n",
    "            # MAX POOL\n",
    "            model.add(\n",
    "                keras.layers.MaxPooling2D(\n",
    "                    pool_size=params['max_pool_size']\n",
    "                )\n",
    "            )\n",
    "            # DROPOUT\n",
    "            if params['dropout_exists']:\n",
    "                # only add a droput layer if param = true\n",
    "                model.add(\n",
    "                    keras.layers.Dropout(\n",
    "                        rate=params['dropout_rate']\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            prev_size = layer_size\n",
    "            \n",
    "        # OUTPUT\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(self.__output_size, activation=\"softmax\"))      \n",
    "\n",
    "        # compile the model\n",
    "        model.compile(optimizer=global_params['optimizer'],\n",
    "                      loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a338091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evolution:\n",
    "    '''\n",
    "    Requires the Genome class using the static functions - instance not required\n",
    "    \n",
    "    Params:\n",
    "        probability (float) the rate of probability eg 1 is 100% and 0.5 is 50%\n",
    "        aggression (float) a higher number gives more weight to the fitter values giving a higher\n",
    "                            probability of these being chosen in the selection function\n",
    "        global_len (int) the length of the global gene in which each paramter represented by a single value\n",
    "        mutation_amount (float [0.0, 0.1]) the amount of mutation to be applied to any gene value \n",
    "        max_depth (int) the maximum depth of any model\n",
    "        metrics (string) the metric used eg 'val_accuracy'\n",
    "    '''\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        probability=0.1,\n",
    "        aggression=2,\n",
    "        global_len=4,  \n",
    "        mutation_amount=0.1,\n",
    "        max_depth=5,\n",
    "        metrics=''\n",
    "    ):\n",
    "        self.__probability = probability\n",
    "        self.__highest_is_fittest = None\n",
    "        self.__aggression = aggression\n",
    "        self.__global_len = global_len \n",
    "        self.__mutation_amount = mutation_amount\n",
    "        self.__max_depth = max_depth\n",
    "        \n",
    "        if metrics in ['accuracy', 'val_accuracy']:\n",
    "            self.__highest_is_fittest = True\n",
    "        elif metrics in ['loss', 'val_loss']:\n",
    "            self.__highest_is_fittest = False\n",
    "        else:\n",
    "            raise ValueError(f'Metric {metrics} not supported')\n",
    "\n",
    "\n",
    "    def probability_test(self):\n",
    "        '''\n",
    "        Returns true if the random number is below that of the rate parameter\n",
    "        This gives a probabilty test for any defined operations\n",
    "        \n",
    "        Returns:\n",
    "            (bool) true if the random number is less than the rate parameter\n",
    "        '''\n",
    "        return True if np.random.rand() < self.__probability else False\n",
    "\n",
    "    def select_fittest(self, fits):\n",
    "        '''\n",
    "        selects the fittest value from a list using the roulette method and returns \n",
    "        the index value of the original source list which can then be applied to a \n",
    "        list of genes or parameters if build using the same order\n",
    "        \n",
    "        parameters:\n",
    "            fits (list float) fitness values for a set of models\n",
    "\n",
    "        returns:\n",
    "            res (int) the index value of the fittest value in the list\n",
    "        '''\n",
    "        # arbitary figure to ensure all significant values are integers\n",
    "        int_scale = 10000\n",
    "        \n",
    "        if self.__highest_is_fittest:\n",
    "            fits = (np.array(fits) * int_scale).astype(int)\n",
    "        else:\n",
    "#           invert the values in order to prioritize the lowest\n",
    "            fits = (1 /np.array(fits) * int_scale).astype(int)\n",
    "        # order the values such that the larger have a wider interval\n",
    "        cum_array = (np.cumsum(np.sort(fits)) * self.__aggression).astype(int)\n",
    "        # choose random int between zero and max of the cum array scaled by the exponent 1/aggression\n",
    "        random_idx = int((np.random.rand() ** (1/self.__aggression)) * cum_array[-1])\n",
    "#         find the corresponding index value within the cum array\n",
    "        idx = np.searchsorted(cum_array, random_idx, side=\"left\")\n",
    "\n",
    "        # Get the sorted indices of the array\n",
    "        sorted_indices = np.argsort(fits)\n",
    "    #     extrapolate back the index to that of the corresponding value in the fits array\n",
    "        res = sorted_indices[idx]\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def point_mutate(self, genome):\n",
    "        '''\n",
    "        Randomly mutates a gene or genes within the given set of genes. \n",
    "        The gene values are either increased or decreased depending on the random number -0.5 to 0.5. \n",
    "\n",
    "        Params:\n",
    "            genome (np.array) the set of genes to be mutated\n",
    "\n",
    "        Returns:\n",
    "            genome (list) the mutated set of genes\n",
    "        '''\n",
    "\n",
    "        for gene in genome:\n",
    "            for i, value in enumerate(gene):\n",
    "                gene[i] = self.mutate_gene_value(value)\n",
    "            \n",
    "        return genome\n",
    "    \n",
    "    def mutate_gene_value(self, gene_value):\n",
    "        '''\n",
    "        mutates a gene value by the scaled amount - mutation_amount\n",
    "        this is either positive or negative depending on the random number\n",
    "        \n",
    "        Params:\n",
    "            gene_value (float) the value to be mutated\n",
    "            \n",
    "        Returns:\n",
    "            gene_value (float) the modified value\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        if self.probability_test():\n",
    "            \n",
    "            mutation = (np.random.rand() - 0.5) * self.__mutation_amount\n",
    "            gene_value = gene_value + mutation\n",
    "            # fix value in the semi closed interval [0.0, 1.0) \n",
    "            # to ensure the index remains within the spec values\n",
    "            gene_value = min(max(gene_value, 0), 0.99)\n",
    "            \n",
    "        return gene_value\n",
    "    \n",
    "    def shrink_mutate(self, genome):\n",
    "        '''\n",
    "        Probabilistically removes one gene to the genes set resulting in one less layer\n",
    "        \n",
    "        Params:\n",
    "            genome (np.array) set of genes to be mutated\n",
    "            \n",
    "        Returns:\n",
    "            genome (np.array) set of genes with len genes or genes - 1\n",
    "        '''\n",
    "        min_depth = 1\n",
    "#         ensure that the deep layer count is always >= 1\n",
    "\n",
    "        depth = self.get_genome_depth(genome)\n",
    "\n",
    "        if depth <= min_depth: return genome\n",
    "\n",
    "        if self.probability_test():\n",
    "            idx = np.random.randint(1, depth)\n",
    "            genome = genome[:-idx]\n",
    "\n",
    "        return genome\n",
    "    \n",
    "    def grow_mutate(self, genome):\n",
    "        '''\n",
    "        Probabilistically adds one gene to the genes set, resulting in another layer\n",
    "        \n",
    "        Params:\n",
    "            genome (np.array) set of genes to be mutated\n",
    "            \n",
    "        Returns:\n",
    "            genome (np.array) set of genes with len genes or genes + 1\n",
    "        '''\n",
    "        new_genome = []\n",
    "        layer_width = len(genome[-1])\n",
    "        depth = self.get_genome_depth(genome)\n",
    "        \n",
    "#       ensure layers never exceeds the maximum number of layers\n",
    "#       split at the global params index to get layers len\n",
    "        if depth >= self.__max_depth:\n",
    "               return genome\n",
    "\n",
    "        if self.probability_test():\n",
    "        # adds a new layer but not exceeding the max layers\n",
    "            new_gene = pn.get_gene(size=layer_width)\n",
    "            genome = genome + list([new_gene])\n",
    "                \n",
    "        return genome\n",
    "    \n",
    "    def crossover(self, genome_1, genome_2):\n",
    "        '''\n",
    "        Merges two genomes at a random point to create a new \"child\" gene\n",
    "        Global genes are allowed to split but layer genes are maintained as a whole\n",
    "        \n",
    "        Params:\n",
    "            gene1 (np.array) single genome\n",
    "            gene2 (np.array) single genome\n",
    "            \n",
    "        Returns:\n",
    "            child (np.array) set of genes with len genes or genes + 1\n",
    "        '''\n",
    "\n",
    "#         simplify the genomes such that the global can be divided\n",
    "        global_len = len(genome_1[0])\n",
    "        # parent 1\n",
    "        p1 = genome_1[0].copy()\n",
    "        p1.extend(genome_1[1:])\n",
    "        # parent 2\n",
    "        p2 = genome_2[0].copy()\n",
    "        p2.extend(genome_2[1:])\n",
    "#         use min() to ensure the index remains in the bounds \n",
    "#         of the smaller gene array and min_gene ensures at least one gene is crossed\n",
    "        min_gene = 1\n",
    "        min_len = len(p1)\n",
    "        split_idx = random.randint(1, random.randint(min_gene, min_len))\n",
    "        merge = p1[:split_idx] + p2[split_idx:]\n",
    "        # reshape into global and layer genes\n",
    "        child = [merge[:global_len]] + merge[global_len:]\n",
    "    \n",
    "        return child\n",
    "    \n",
    "    def get_genome_depth(self, genome):\n",
    "        '''\n",
    "        get the length of the genome representing its number of conv layers\n",
    "        '''\n",
    "#         return the number of layers minus the global gene\n",
    "        return len(genome) - 1\n",
    "    \n",
    "    def get_next_generation(self, fits, pop):\n",
    "        '''\n",
    "        create a population of the size defined in the class parameters\n",
    "        \n",
    "        Params:\n",
    "            fits (array) set of floats taken from each models evaluation performance\n",
    "            pop (2d array) the current population under evaluation\n",
    "            \n",
    "        Returns:\n",
    "            next_generation (list) the next generation of genomes\n",
    "        '''\n",
    "\n",
    "        next_generation = []\n",
    "        for i in range(len(fits)):\n",
    "\n",
    "#             find the index two fit parents\n",
    "            p1 = self.select_fittest(fits)\n",
    "            p2 = self.select_fittest(fits)\n",
    "\n",
    "#             get the genome of each parent\n",
    "            gn1 = pop[p1].copy()\n",
    "            gn2 = pop[p2].copy()\n",
    "            \n",
    "#             mate the parents\n",
    "            child = self.crossover(gn1, gn2)\n",
    "#             print(child)\n",
    "    #             apply the point mutation to the child\n",
    "            child = self.point_mutate(child)\n",
    "    #             grow, shrink or retain the depth using the probability applied within the functions\n",
    "            size_mutate = {\n",
    "                1: self.grow_mutate(child),\n",
    "                2: self.shrink_mutate(child),\n",
    "                3: child}\n",
    "            p = np.random.randint(1, 4)\n",
    "            child = size_mutate[p]\n",
    "\n",
    "            next_generation.append(child.copy())\n",
    "            \n",
    "        return next_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45614a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GA_Optimizer:\n",
    "    '''\n",
    "    handles the overall running of the GA by getting the population, fitting each genome\n",
    "    then create the next generation and repeat until the max number of generations has\n",
    "    been reached\n",
    "    \n",
    "    Parameters:\n",
    "        model_builder (Model_Constructor class) handles building the models\n",
    "        population_class (Population class) handles the population and mapping\n",
    "        evolution_class (Evolution class) handle the creation of successive generations\n",
    "        validation_split (float) the train/validation split eg 0.2 is an 80/20 split repectively\n",
    "        callbacks (keras.callbacks) callbacks to be used eg early stopping\n",
    "        metrics (string) the value used for validation ['accuracy', 'val_accuracy', 'loss', 'val_loss']\n",
    "    '''\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        X, y, \n",
    "        model_builder=None,\n",
    "        population_class=None,\n",
    "        evolution_class=None,\n",
    "        validation_split=0.2, \n",
    "        callbacks=[],  \n",
    "        metrics='accuracy'\n",
    "    ):\n",
    "        self.__X = X\n",
    "        self.__y = y\n",
    "        self.__build_model = model_builder\n",
    "        self.__pn = population_class\n",
    "        self.__ev = evolution_class\n",
    "        self.__validation_split = validation_split\n",
    "        self.__callbacks = callbacks\n",
    "        self.__metrics = metrics\n",
    "        \n",
    "        assert model_builder\n",
    "        assert type(population_class) == Population\n",
    "        assert type(evolution_class) == Evolution\n",
    "    \n",
    "    def test_population(self, mapped_population=[], max_epochs=20, monitor_string=\"\"):\n",
    "        '''\n",
    "        Loops through an entire mapped population and fits a model using the hyper parameters\n",
    "        \n",
    "        Params:\n",
    "            mapped_population (list) a list of dicts containing the hyper parameters for each model \n",
    "            max_epochs (int) the most epochs used for training any model\n",
    "            monitor_string (string) used for updating the status display\n",
    "            \n",
    "        Returns:\n",
    "            generation_results (list) each result from the generation under test\n",
    "            best_in_generation (dict) the mapped parameters of the best in the generation\n",
    "        '''\n",
    "        generation_results = []\n",
    "        best_so_far = 0\n",
    "        \n",
    "        for idx, genome in enumerate(mapped_population):\n",
    "            # get batch size or default to 64\n",
    "            batch_size = genome['global_params'].get('batch_size', 64)\n",
    "            # build model with mapped genome using callback function\n",
    "            model = self.__build_model(genome)\n",
    "            \n",
    "            # update screen status\n",
    "            clear_output()\n",
    "            print(f'{monitor_string}\\n')\n",
    "   \n",
    "            print(f'Genome   \\t| {idx + 1} of {len(mapped_population)}')\n",
    "            print(f'Depth \\t\\t| {len(genome) - 1}')\n",
    "            print(f'Batch size \\t| {batch_size}')\n",
    "            print(f'Best {self.__metrics}\\t| {best_so_far}\\n')\n",
    "            \n",
    "#           train the model using the given split\n",
    "            model.fit(\n",
    "                self.__X,\n",
    "                self.__y,\n",
    "                epochs=max_epochs, \n",
    "                validation_split=self.__validation_split, \n",
    "                batch_size=batch_size, \n",
    "                callbacks=[self.__callbacks],\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # get results\n",
    "            genome_results = model.history.history[self.__metrics]\n",
    "            # get the best in current genome (either lowest or highest from the history)\n",
    "            best_in_genome, _ = self.get_best_result(self.__metrics, genome_results)\n",
    "            generation_results.append(best_in_genome)\n",
    "            # used for the screen update\n",
    "            best_so_far, _ = self.get_best_result(self.__metrics, generation_results)\n",
    "            \n",
    "        # get the best the current generation\n",
    "        best_in_generation, _ = self.get_best_result(self.__metrics, generation_results)\n",
    "        return generation_results, best_in_generation\n",
    "    \n",
    "    def get_best_result(self, metric, results_list):\n",
    "        '''\n",
    "        depending on the metric either the highest of lowest is returned \n",
    "        \n",
    "        Params:\n",
    "            metric (string) the metric used throughout\n",
    "            results_list (list) the values from which to choose the best result\n",
    "        \n",
    "        Returns:\n",
    "            result (list element) the value representing the best result\n",
    "            idx (int) the index of the best result\n",
    "            \n",
    "        '''\n",
    "        if metric in ['accuracy', 'val_accuracy']:\n",
    "            result = max(results_list)\n",
    "            idx = np.argmax(results_list)\n",
    "        elif metric in ['loss', 'val_loss']:\n",
    "            result = min(results_list)\n",
    "            idx = np.argmin(results_list)\n",
    "        else:\n",
    "            result = None\n",
    "            idx = None\n",
    "        return result, idx\n",
    "        \n",
    "    def evolve_generations(\n",
    "        self, \n",
    "        generations=5, \n",
    "        init_epochs=20, \n",
    "        pop_size=10, \n",
    "        epoch_increment=0,\n",
    "        test_name=\"test\"\n",
    "    ):\n",
    "        '''\n",
    "        loops through to the number of generations, selecting the fittest each time\n",
    "        the status display is updatated each iteration and the current results are\n",
    "        saved to file, overwriting each time\n",
    "        The next generation is created using the Evolution class to a size of pop_size - 1\n",
    "        after which the parameters of the previous generations fittest model are added back.\n",
    "        This ensures that the fittest model is preserved, unchanged, as a baseline for the next gen\n",
    "        \n",
    "        Params:\n",
    "            generations (int) the number of iterations of the loop\n",
    "            init_epochs (int) the number of epochs used for the first generations fit\n",
    "            pop_size (int) the number of genomes to exist in any population\n",
    "            epoch_increment (int) this value is added to init_epochs at each iteration\n",
    "                thus training each successive generation for more epochs\n",
    "                \n",
    "        Returns:\n",
    "            results_dict (dict) the results for each generation's training and the parameters of the fittest\n",
    "        '''\n",
    "        \n",
    "        # get initial population\n",
    "        epochs = init_epochs\n",
    "        best_epochs = []\n",
    "        pop = pn.get_population(pop_size)\n",
    "        mapped_population = pn.map_population(pop)\n",
    "        best_so_far = 0\n",
    "        \n",
    "        results_dict = {\n",
    "            'Best_parameters': [],\n",
    "            f'Best_{self.__metrics}': [],\n",
    "            f'Generation_{self.__metrics}': [],\n",
    "            'Best_so_far': [],\n",
    "            'Epochs' : []\n",
    "        }\n",
    "        \n",
    "        for generation in range(generations):\n",
    "             # update status on screen\n",
    "            monitor_string = f'Generation\\t| {generation + 1} of {generations}\\n'\n",
    "            monitor_string += f'Max epochs \\t| {epochs}\\n'\n",
    "            monitor_string += f'Best so far\\t| {best_so_far}\\n'\n",
    "            \n",
    "            print(f'{monitor_string}\\t')\n",
    "            # test the generation and get the results back\n",
    "            fits, best_result = self.test_population(\n",
    "                mapped_population, max_epochs=epochs,\n",
    "                monitor_string=monitor_string\n",
    "            )\n",
    "\n",
    "#             get the index of the fittest for the generation\n",
    "            fittest, fittest_idx = self.get_best_result(self.__metrics, fits)\n",
    "#             get the fittest of the current generation\n",
    "            best_genome = pop[fittest_idx]\n",
    "            best_params = mapped_population[fittest_idx]\n",
    "            \n",
    "            # decrease the population size\n",
    "#             pop_len = pop_len - 1\n",
    "            # get next generation of size n-1\n",
    "            pop = self.__ev.get_next_generation(fits, pop)[:-1]\n",
    "            # retain the fittest of the previous generation without mutation\n",
    "            pop.append(best_genome)\n",
    "            # map the next geration for testing\n",
    "            mapped_pop = self.__pn.map_population(pop)\n",
    "            \n",
    "            # populate the dict with results\n",
    "            results_dict['Best_parameters'].append(best_params)\n",
    "            results_dict[f'Best_{self.__metrics}'].append(fittest) \n",
    "            results_dict[f'Generation_{self.__metrics}'].append(fits)\n",
    "            results_dict['Epochs'].append(epochs)\n",
    "            # update for status display\n",
    "            best_so_far, _ = self.get_best_result(\n",
    "                self.__metrics, results_dict[f'Best_{self.__metrics}']\n",
    "            \n",
    "            )                \n",
    "            results_dict['Best_so_far'].append(best_so_far)\n",
    "            \n",
    "            # save each run in case of a crash\n",
    "            self.save_dict(results_dict, test_name)\n",
    "            # increase the number of epochs incrementally\n",
    "            epochs = epochs + epoch_increment\n",
    "\n",
    "            \n",
    "        return results_dict\n",
    "    \n",
    "    def save_dict(self, result, name):\n",
    "        '''\n",
    "        saves the given dict to a json file\n",
    "        \n",
    "        Params:\n",
    "            result (dict) the dict which needs to be serialized\n",
    "            name (string) the filename to be used\n",
    "        '''\n",
    "        filename = CURRENT_DIR\n",
    "        filename += '/ga_results/'\n",
    "        filename += f'{name}.json'\n",
    "\n",
    "        f = open(filename, \"w\")\n",
    "\n",
    "        json.dump(result, f, indent = 6)\n",
    "\n",
    "        f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea2c2239",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics='val_accuracy'\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(\n",
    "        monitor=metrics, \n",
    "        patience=3,\n",
    "        mode='auto',\n",
    "        verbose=1,\n",
    "        start_from_epoch=2,\n",
    ")]\n",
    "\n",
    "# population to create the inital population and mappings\n",
    "pn = Population(max_depth=4)   \n",
    "# new model constructor to handle the build and training of each genome\n",
    "mc = Model_Constructor(shape=dh.shape, output_size=5)\n",
    "# new evloution class to handle the genes\n",
    "ev = Evolution(\n",
    "    probability=0.25, mutation_amount=0.1, max_depth=4, metrics=metrics\n",
    ")\n",
    "\n",
    "X = dh.X_train\n",
    "y = dh.y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea96819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation\t| 5 of 10\n",
      "Max epochs \t| 10\n",
      "Best so far\t| 0.9687362313270569\n",
      "\n",
      "\n",
      "Genome   \t| 2 of 10\n",
      "Depth \t\t| 1\n",
      "Batch size \t| 64\n",
      "Best val_accuracy\t| 0.9669749140739441\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m 74/142\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 1s/step - accuracy: 0.3460 - loss: 61.5717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 21:53:24.182039: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: desired shape must be a DT_INT32 or DT_INT64 vector, not a float\n",
      "\t [[{{function_node __inference_one_step_on_data_312790}}{{node sequential_54_1/conv2d_123_1/Reshape}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_54_1/conv2d_123_1/Reshape defined at (most recent call last):\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/r1/l7_r9m05287g2rmr86b9xwsc0000gn/T/ipykernel_63074/2779201738.py\", line 13, in <module>\n\n  File \"/var/folders/r1/l7_r9m05287g2rmr86b9xwsc0000gn/T/ipykernel_63074/3313223757.py\", line 114, in evolve_generations\n\n  File \"/var/folders/r1/l7_r9m05287g2rmr86b9xwsc0000gn/T/ipykernel_63074/3313223757.py\", line 47, in test_population\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 51, in train_step\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/models/sequential.py\", line 209, in call\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/models/functional.py\", line 556, in call\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 252, in call\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/ops/numpy.py\", line 4440, in reshape\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1789, in reshape\n\ndesired shape must be a DT_INT32 or DT_INT64 vector, not a float\n\t [[{{node sequential_54_1/conv2d_123_1/Reshape}}]] [Op:__inference_one_step_on_iterator_312869]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# use the time so as to not inadvertantly overwrite previous tests\u001b[39;00m\n\u001b[1;32m     11\u001b[0m test_name \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve_generations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_increment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_name\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 114\u001b[0m, in \u001b[0;36mGA_Optimizer.evolve_generations\u001b[0;34m(self, generations, init_epochs, pop_size, epoch_increment, test_name)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonitor_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    113\u001b[0m             \u001b[38;5;66;03m# test the generation and get the results back\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m             fits, best_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_population\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmapped_population\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmonitor_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonitor_string\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m#             get the index of the fittest for the generation\u001b[39;00m\n\u001b[1;32m    120\u001b[0m             fittest, fittest_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_best_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__metrics, fits)\n",
      "Cell \u001b[0;32mIn[18], line 47\u001b[0m, in \u001b[0;36mGA_Optimizer.test_population\u001b[0;34m(self, mapped_population, max_epochs, monitor_string)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__metrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m| \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_so_far\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#           train the model using the given split\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m             \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__validation_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__callbacks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;66;03m# get results\u001b[39;00m\n\u001b[1;32m     58\u001b[0m             genome_results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__metrics]\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_54_1/conv2d_123_1/Reshape defined at (most recent call last):\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/r1/l7_r9m05287g2rmr86b9xwsc0000gn/T/ipykernel_63074/2779201738.py\", line 13, in <module>\n\n  File \"/var/folders/r1/l7_r9m05287g2rmr86b9xwsc0000gn/T/ipykernel_63074/3313223757.py\", line 114, in evolve_generations\n\n  File \"/var/folders/r1/l7_r9m05287g2rmr86b9xwsc0000gn/T/ipykernel_63074/3313223757.py\", line 47, in test_population\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 51, in train_step\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/models/sequential.py\", line 209, in call\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/models/functional.py\", line 556, in call\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 252, in call\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/ops/numpy.py\", line 4440, in reshape\n\n  File \"/Users/jodywright/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1789, in reshape\n\ndesired shape must be a DT_INT32 or DT_INT64 vector, not a float\n\t [[{{node sequential_54_1/conv2d_123_1/Reshape}}]] [Op:__inference_one_step_on_iterator_312869]"
     ]
    }
   ],
   "source": [
    "optimizer = GA_Optimizer(\n",
    "    X=X, \n",
    "    y=y, \n",
    "    model_builder=mc.build_model, \n",
    "    population_class = pn,\n",
    "    evolution_class = ev,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "# use the time so as to not inadvertantly overwrite previous tests\n",
    "test_name = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "results = optimizer.evolve_generations(\n",
    "    generations=10, \n",
    "    init_epochs=2, \n",
    "    pop_size=10, \n",
    "    epoch_increment=2,\n",
    "    test_name=test_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b49c506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_params': {'learning_rate': 0.0001,\n",
       "  'optimizer': 'adam',\n",
       "  'start_size': 24,\n",
       "  'batch_size': 128},\n",
       " 'layer_params': {1: {'filter_size': 1.2,\n",
       "   'filter_step': 2,\n",
       "   'filter_activation': 'relu',\n",
       "   'dropout_exists': True,\n",
       "   'dropout_rate': 0.4,\n",
       "   'max_pool_exists': False,\n",
       "   'max_pool_size': 3},\n",
       "  2: {'filter_size': 1.8,\n",
       "   'filter_step': 14,\n",
       "   'filter_activation': 'relu',\n",
       "   'dropout_exists': False,\n",
       "   'dropout_rate': 0.3,\n",
       "   'max_pool_exists': False,\n",
       "   'max_pool_size': 2}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the best parameters from the last generation\n",
    "results['Best_parameters'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40498d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.44999998807907104, 0.44999998807907104]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[f'Best_{metrics}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f360873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = results['Best_parameters'][-1]\n",
    "# rebuild for over fit point\n",
    "model = mc.build_model(params)\n",
    "vaidation_split = 0.2\n",
    "\n",
    "\n",
    "batch_size = params['global_params']['batch_size']\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=3,\n",
    "        mode='auto'\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38fc3e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_55\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_55\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">279</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_127               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_128               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132750</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">663,755</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_127 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m279\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m28\u001b[0m)   │           \u001b[38;5;34m280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_127               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m28\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m28\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_128 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │        \u001b[38;5;34m12,650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_128               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_55 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132750\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │       \u001b[38;5;34m663,755\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">676,685</span> (2.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m676,685\u001b[0m (2.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">676,685</span> (2.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m676,685\u001b[0m (2.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1406b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.3600 - loss: 735.3976 - val_accuracy: 0.1629 - val_loss: 1.6012\n",
      "Epoch 2/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.8352 - loss: 0.5069 - val_accuracy: 0.7349 - val_loss: 1.2737\n",
      "Epoch 3/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.8928 - loss: 0.3713 - val_accuracy: 0.8340 - val_loss: 0.8249\n",
      "Epoch 4/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.9109 - loss: 0.2950 - val_accuracy: 0.8516 - val_loss: 0.5217\n",
      "Epoch 5/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.9204 - loss: 0.2695 - val_accuracy: 0.7583 - val_loss: 0.9471\n",
      "Epoch 6/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.9121 - loss: 0.2816 - val_accuracy: 0.8736 - val_loss: 0.4228\n",
      "Epoch 7/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.9419 - loss: 0.1966 - val_accuracy: 0.8657 - val_loss: 0.4210\n",
      "Epoch 8/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.9477 - loss: 0.1785 - val_accuracy: 0.8639 - val_loss: 0.4102\n",
      "Epoch 9/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.9453 - loss: 0.1753 - val_accuracy: 0.8842 - val_loss: 0.3325\n",
      "Epoch 10/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.9491 - loss: 0.1646 - val_accuracy: 0.9397 - val_loss: 0.1827\n",
      "Epoch 11/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.9623 - loss: 0.1378 - val_accuracy: 0.9419 - val_loss: 0.2239\n",
      "Epoch 12/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.9630 - loss: 0.1242 - val_accuracy: 0.9441 - val_loss: 0.1866\n",
      "Epoch 13/40\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.9679 - loss: 0.1086 - val_accuracy: 0.9260 - val_loss: 0.2258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x5c78eac20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find overfit point\n",
    "model.fit( \n",
    "    X, y, epochs=40, validation_split=0.2, batch_size=batch_size, verbose=1, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a70ac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.3687 - loss: 1156.2755\n",
      "Epoch 2/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.4545 - loss: 1.4174\n",
      "Epoch 3/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.4963 - loss: 1.2953\n",
      "Epoch 4/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.4925 - loss: 1.2890\n",
      "Epoch 5/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.5137 - loss: 1.2456\n",
      "Epoch 6/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8180 - loss: 0.6090\n",
      "Epoch 7/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8711 - loss: 0.4419\n",
      "Epoch 8/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8857 - loss: 0.3770\n",
      "Epoch 9/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8984 - loss: 0.3529\n",
      "Epoch 10/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.9129 - loss: 0.3130\n",
      "Epoch 11/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.9135 - loss: 0.3207\n",
      "Epoch 12/12\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.9199 - loss: 0.2852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x4f6e92830>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuild and train on entire set\n",
    "model = mc.build_model(params)\n",
    "model.fit( \n",
    "    X, y, epochs=12, validation_split=0, batch_size=batch_size, verbose=1, callbacks=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51d8d467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 241ms/step - accuracy: 0.7209 - loss: 1.3406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3371020555496216, 0.7290345430374146]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dh.X_test, dh.y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be12912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA_Optimizer:\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.__X = X\n",
    "        self.__y = y\n",
    "        \n",
    "    def test_population(self):\n",
    "        pass\n",
    "    \n",
    "    def evolve_the_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '2024-08-25-17-30'\n",
    "filename = f'{CURRENT_DIR}/ga_results/{name}.json'\n",
    "# filename += '/ga_results/'\n",
    "# filename += f'{name}.json'\n",
    "\n",
    "f = open(filename)\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "f.close()\n",
    "data['Best_parameters'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189271f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pn.get_population(pop_size=5)\n",
    "\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results, best_epochs = test_population(\n",
    "    population=pop, X=X, y=y, max_epochs=2, validation_split=0.2, callbacks=[], monitor_string=\"Test\"\n",
    ")\n",
    "print(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8869e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see twitter bookmark\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "with alive_bar() as bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9107be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(X, y, batch_size=g['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c82a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484724dd",
   "metadata": {},
   "source": [
    "### Repeatability\n",
    "- The default initializer is random_glorot with a default seed=None.   \n",
    "- This, according to keras, produces a deterministic set of values https://keras.io/api/layers/initializers/  \n",
    "- \"Note that an initializer seeded with an integer or None (unseeded) will produce the same random values across multiple calls\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e819c",
   "metadata": {},
   "source": [
    "### For the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498ae90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop = pn.get_population(pop_size=5)\n",
    "genome = pop[0]\n",
    "pprint.pp(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f75ee57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_params, layer_params = mc.get_param_dict(genome)\n",
    "pprint.pp(global_params)\n",
    "pprint.pp(layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mc.build_model(global_params, layer_params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdac55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = [0.5,0.3,1,0.6,0.1]\n",
    "next_gen = ev.get_next_generation(fits, pop)\n",
    "print(f'Pop size: {[len(g) for g in pop]}')\n",
    "print(f'Next gen: {[len(g) for g in next_gen]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "child = ev.crossover(pop[0].copy(), pop[1].copy())\n",
    "child\n",
    "# ev.point_mutate(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77285f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "child = []\n",
    "c1 = pop[0][:idx].copy()\n",
    "c2 = pop[1][idx:].copy()\n",
    "print(f'{c1}\\n{c2}')\n",
    "\n",
    "child.extend(c1)\n",
    "child.extend(c2)\n",
    "print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# fits = [30, 20,10,10000,500,600,700,0.1]\n",
    "# fits = [0.4,0.3,0.6,0.1,0.7,0.2,0.18,0.1]\n",
    "fits = [1,2,3,4,5]\n",
    "# fits = best_results\n",
    "results = []\n",
    "pop = pn.get_population(pop_size=20)\n",
    "for i in range(1000):\n",
    "    res = ev.select_fittest(fits)\n",
    "    results.append(fits[res])\n",
    "    \n",
    "unique, counts = np.unique(results, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c69ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ev.select_fittest(best_results)\n",
    "print(best_results, best_results[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop = pn.get_population(pop_size=5)\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a61b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop_test = pn.get_population(pop_size=10)\n",
    "c1 = pop_test[0]\n",
    "c2 = pop_test[1]\n",
    "print(f'C1{c1}\\n\\nC2{c2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656909a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c0, idx = ev.crossover(c1, c2)\n",
    "print(f'idx: {idx}\\n\\nC0{c0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db174b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mutated_genome = ev.grow_mutate(c1)\n",
    "mutated_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutated_genome = ev.shrink_mutate(c1)\n",
    "mutated_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = c1.copy()\n",
    "mutated_genome = ev.point_mutate(genome)\n",
    "mutated_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2578293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use in the model builder to assign a default in the case of a missing parameter\n",
    "d = {'test':100}\n",
    "d.get('t', 'default')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6016a1e3",
   "metadata": {},
   "source": [
    "# Redundant Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# class Model_Handler:\n",
    "    \n",
    "#     def __init__(self, shape, output_size, global_size, layer_size):\n",
    "#         self.__shape = shape\n",
    "#         self.__output_size = output_size\n",
    "#         # the size of the global parameters eg global_params = params[:global_size]\n",
    "#         self.__global_size = global_size\n",
    "#         # the size of each layer's parameters eg n arrays of width layer_size\n",
    "#         self.__layer_size = layer_size\n",
    "\n",
    "# #     def build_model(self, global_params, layer_params):\n",
    "        \n",
    "# #         # used for the scaling of each filter size\n",
    "# #         prev_size = global_params[2]\n",
    "# #         # new empty model\n",
    "# #         model = keras.Sequential()\n",
    "# #         # set the input shape\n",
    "# #         model.add(keras.Input(shape=self.__shape))\n",
    "# #         # using a reshaped layer parameter array loop each and apply\n",
    "# #         for size_scale, dropout, rate in layer_params:\n",
    "# #             layer_size = int(size_scale * prev_size)\n",
    "# #             # set the layer size as a multiple of the previous using the size_scale param\n",
    "# #             model.add(keras.layers.Conv2D(filters=layer_size, kernel_size=3, activation=\"relu\"))\n",
    "# #             model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "# #             # only add a droput layer if param = true\n",
    "# #             if dropout:\n",
    "# #                 model.add(keras.layers.Dropout(rate=rate))\n",
    "\n",
    "# #             prev_size = layer_size\n",
    "\n",
    "# #         # add the final layers of the model\n",
    "# #         model.add(keras.layers.Flatten())\n",
    "# #         model.add(keras.layers.Dense(self.__output_size, activation=\"softmax\"))      \n",
    "\n",
    "# #         # compile the model\n",
    "# #         model.compile(optimizer=\"rmsprop\",\n",
    "# #                       loss=\"sparse_categorical_crossentropy\",\n",
    "# #                       metrics=[\"accuracy\"])\n",
    "\n",
    "# #         return model\n",
    "    \n",
    "#     def train_model(model, X, y, epochs, split, batch, callbacks):\n",
    "#         model.fit(\n",
    "#         dh.X_train[:1000], \n",
    "#         dh.y_train[:1000], \n",
    "#         epochs=max_epochs, \n",
    "#         validation_split=val_split, \n",
    "#         batch_size=batch_size, \n",
    "#         callbacks=[callbacks]\n",
    "#     )\n",
    "        \n",
    "#     def test_population(self, population):\n",
    "#         # split into global and layer params\n",
    "#         global_params = params[:self.__global_size]\n",
    "#         layer_params = np.array(params[self.__global_size:]).reshape(self.__layer_shape)\n",
    "        \n",
    "#         for genome in population:\n",
    "#             print(genome)\n",
    "# #             model = self.build_model(global_params, layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf161cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# mh = Model_Handler(\n",
    "#     shape=(281, 362, 1), \n",
    "#     output_size=5, \n",
    "#     global_size=population.global_size, \n",
    "#     layer_shape=population.layer_shape\n",
    "# )\n",
    "# # model = mh.build_model(global_params, layer_params)\n",
    "# # model.summary()\n",
    "\n",
    "# mh.test_population(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# # set the params\n",
    "# max_epochs = 5\n",
    "# vaidation_split = 0.2\n",
    "# batch_size = 256\n",
    "\n",
    "# # create the callbacks\n",
    "# monitor = 'val_loss'\n",
    "# checkpoint_path = 'checkpoint_path.keras'\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(\n",
    "#         monitor=monitor, \n",
    "#         patience=3\n",
    "#     ),\n",
    "    \n",
    "# #     keras.callbacks.ModelCheckpoint(\n",
    "# #         filepath=checkpoint_path, \n",
    "# #         monitor=monitor, \n",
    "# #         save_best_only=True\n",
    "# #     )\n",
    "# ]\n",
    "\n",
    "# model.fit(\n",
    "#     dh.X_train[:1000], \n",
    "#     dh.y_train[:1000], \n",
    "#     epochs=max_epochs, \n",
    "#     validation_split=vaidation_split, \n",
    "#     batch_size=batch_size, \n",
    "#     callbacks=[callbacks]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e1eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# initializer = keras.initializers.Ones()\n",
    "# layer = keras.layers.Conv2D(filters=layer_size, kernel_size=3, activation=\"relu\", kernel_initializer=initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ebac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # population to create the inital population and mappings\n",
    "# pn = Population(max_depth=4)   \n",
    "# # new model constructor to handle the build and training of each genome\n",
    "# mc = Model_Constructor(shape=dh.shape, output_size=5)\n",
    "# # new evloution class to handle the genes\n",
    "# ev = Evolution(probability=0.5, highest_is_fittest=False, mutation_amount=0.1, max_depth=4)\n",
    "\n",
    "# # for the puprose of testing set the seed to the usual answer to life the universe and everything\n",
    "# keras.utils.set_random_seed(42)\n",
    "# # use the time so as to not inadvertantly overwrite previous tests\n",
    "# test_name = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "# X = dh.X_train\n",
    "# y = dh.y_train\n",
    "\n",
    "# results = evolve_the_model(\n",
    "#     X=X, y=y, \n",
    "#     generations=10, \n",
    "#     pop_size=10, \n",
    "#     start_epochs=2, \n",
    "#     epoch_factor=1, \n",
    "#     fitness_func=ev.get_next_generation,\n",
    "#     test_name=test_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0234149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_population(\n",
    "#     mapped_pop, \n",
    "#     X, y, \n",
    "#     max_epochs, \n",
    "#     validation_split=0.2, \n",
    "#     callbacks=[], \n",
    "#     monitor_string=\"\", \n",
    "#     metrics='accuracy'\n",
    "# ):\n",
    "    \n",
    "#     best_results = []\n",
    "#     best_epochs = []\n",
    "#     best_so_far = float(\"inf\")\n",
    "\n",
    "#     for i, genome in enumerate(mapped_pop):\n",
    "#         # map the gene and build the model\n",
    "#         model = mc.build_model(genome, metrics)\n",
    "#         g = genome['global_params']\n",
    "#         l = genome['layer_params']\n",
    "#         # monitor metrics \n",
    "#         depth = len(l.keys())\n",
    "#         batch_size = g['batch_size']\n",
    "        \n",
    "#         # process update to user\n",
    "#         clear_output()\n",
    "#         print(f'{monitor_string}')\n",
    "#         print(f'Genome   \\t| {i + 1} of {len(mapped_pop)}')\n",
    "#         print(f'Depth \\t\\t| {depth}')\n",
    "#         print(f'Batch size \\t| {batch_size}\\n')\n",
    "#         print(f'Best this gen  {best_so_far}\\n')\n",
    "        \n",
    "#         # fit to the data \n",
    "#         model.fit( \n",
    "#                     X, \n",
    "#                     y,\n",
    "#                     epochs=max_epochs, \n",
    "#                     validation_split=validation_split, \n",
    "#                     batch_size=g['batch_size'], \n",
    "#                     callbacks=[callbacks],\n",
    "#                     verbose=1\n",
    "#                 )\n",
    "        \n",
    "#         # get the training history\n",
    "#         hist = model.history.history['loss']\n",
    "#     #   store best fitness and the best epoch for survival of the fittest\n",
    "#         best_result = min(hist)\n",
    "#         # for monitoring during the test\n",
    "#         best_so_far = min(best_so_far, best_result)\n",
    "#         # for output for use in the Evolution class\n",
    "#         best_epochs.append(len(hist))\n",
    "#         best_results.append(best_result)\n",
    "        \n",
    "        \n",
    "#     return best_results, best_epochs\n",
    "    \n",
    "\n",
    "# def evolve_the_model(\n",
    "#     X, y, generations, pop_size, start_epochs, epoch_factor, fitness_func, test_name):\n",
    "    \n",
    "#     # create the callbacks\n",
    "#     metrics = 'val_accuracy'\n",
    "\n",
    "#     callbacks = [keras.callbacks.EarlyStopping(\n",
    "#             monitor=metrics, \n",
    "#             patience=3,\n",
    "#             mode='auto'\n",
    "#     )]\n",
    "#     results = {}\n",
    "#     file_path = 'ga_results.json'\n",
    "    \n",
    "#     epochs=start_epochs\n",
    "#     # for monitoring\n",
    "#     best_so_far = float(\"inf\")\n",
    "#     # get initial population of size n\n",
    "#     pop = pn.get_population(size=pop_size)\n",
    "#     mapped_pop = pn.map_population(pop)\n",
    "    \n",
    "#     results = {\n",
    "#         'Best_parameters': [],\n",
    "#         'Best_fitness': [],\n",
    "#         'Fitness_values': [],\n",
    "#         'Best_so_far': [],\n",
    "#         'Best_epochs' : []\n",
    "#     }\n",
    "#     # evolve for the number of generations\n",
    "#     for generation in range(generations):\n",
    "        \n",
    "#         monitor_string = f'Generation\\t| {generation + 1} of {generations}\\n'\n",
    "#         monitor_string += f'Max epochs \\t| {epochs}\\n'\n",
    "#         monitor_string += f'Best so far\\t| {best_so_far}\\n'\n",
    "        \n",
    "#         fits, best_epochs = test_population(\n",
    "#             mapped_pop=mapped_pop, \n",
    "#             X=X, \n",
    "#             y=y, \n",
    "#             max_epochs=epochs, \n",
    "#             validation_split=0.2, \n",
    "#             callbacks=callbacks, \n",
    "#             monitor_string=monitor_string,\n",
    "#             metrics=metrics\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#         fittest = min(fits)\n",
    "#         best_so_far = min(best_so_far, fittest)\n",
    "#         best_genome = pop[np.argmin(fits)]\n",
    "#         best_params = mapped_pop[np.argmin(fits)]\n",
    "\n",
    "#         results['Best_parameters'].append(best_params)\n",
    "#         results['Best_fitness'].append(fittest) \n",
    "#         results['Fitness_values'].append(fits)\n",
    "#         results['Best_epochs'].append(best_epochs)\n",
    "#         results['Best_so_far'].append(best_so_far)\n",
    "        \n",
    "#         # save each run in case of a crash\n",
    "#         save_dict(results, test_name)\n",
    "#         # increase the number of epochs incrementally\n",
    "#         epochs = epochs + epoch_factor\n",
    "#     # get next pop from the Evolution class of size n-1\n",
    "#     # add back the fittest of the previous generation\n",
    "#         pop = fitness_func(fits, pop)[:-1]\n",
    "#         pop.append(best_genome)\n",
    "#         mapped_pop = pn.map_population(pop)\n",
    "#     return results\n",
    "#     # can also reduce the population using the same idea - try as an experiment\n",
    "    \n",
    "#     # also try using the early stopping as a bespoke in that if performance has\n",
    "#     # not improved for n generations then end\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "ml3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
