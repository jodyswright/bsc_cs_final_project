{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf48f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files of size:\n",
      "Images: (14190, 281, 362, 1)\n",
      "Labels: (14190,)\n",
      "(11352, 281, 362, 1) (2838, 281, 362, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# pip install tensorflow Version: 2.17.0\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras import models, layers\n",
    "\n",
    "# Version: 3.4.1\n",
    "from tensorflow import keras\n",
    "\n",
    "# use for splitting the test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from scipy import spatial\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for the creation of the cartesian product grid\n",
    "from itertools import product\n",
    "\n",
    "# for the timing of each test\n",
    "import time\n",
    "\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "\n",
    "# the data tools module\n",
    "import data_tools as dt\n",
    "dh = dt.Data_Handling(output_size=5)\n",
    "\n",
    "# set the paths to load the processed data\n",
    "CURRENT_DIR = os.curdir\n",
    "label_path = f'{CURRENT_DIR}/data/mitdb_labels_reduced.npy'\n",
    "data_path = f'{CURRENT_DIR}/data/mitdb_data_reduced.npy'\n",
    "\n",
    "# get the data\n",
    "dh.load_data(label_path=label_path, data_path=data_path)\n",
    "\n",
    "# split into train and test sets\n",
    "dh.split_data(split=0.2)\n",
    "\n",
    "print(dh.X_train.shape, dh.X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d684aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population:\n",
    "    '''\n",
    "    Class to create a population of genomes with each containing genes of random float values\n",
    "    \n",
    "    attributes:\n",
    "        layer_size\n",
    "        layer_shape\n",
    "    '''\n",
    "    def __init__(self, max_depth=5):\n",
    "        \n",
    "        self.__max_depth = max_depth\n",
    "\n",
    "        self.__global_spec = {\n",
    "            'learning_rate':[0.1, 0.01, 0.001, 0.0001],\n",
    "            'optimizer':['adam', 'sgd'],\n",
    "            'start_size':list(range(8, 33, 8)),\n",
    "            'batch_size':list(range(64, 257, 32))\n",
    "        }\n",
    "        self.__layer_spec = {\n",
    "            'filter_size':[i/10 for i in range(11, 20)],\n",
    "            'filter_activation': ['relu'],\n",
    "            'dropout_exists': [True, False],\n",
    "            'dropout_rate': [i/10 for i in range(2, 6, 1)],\n",
    "            'max_pool_exists': [True, False],\n",
    "            'max_pool_size' : [2, 3]\n",
    "        }\n",
    "    \n",
    "    def get_genome(self, depth=1):\n",
    "        '''\n",
    "        Creates a genome to include a global gene and at least 1 layer\n",
    "        \n",
    "        Params:\n",
    "            depth (int) the number of layers within the genome\n",
    "\n",
    "        Returns:\n",
    "            (np.array) a set of genes\n",
    "        '''\n",
    "        assert depth >= 1, \"Size must be at least 1\"\n",
    "\n",
    "        # global gene\n",
    "        genome = []\n",
    "        genome.append(self.get_gene(len(self.__global_spec)))\n",
    "        # layer genes\n",
    "        [genome.append(self.get_gene(len(self.__layer_spec))) for g in range(depth)]\n",
    "        \n",
    "        return genome\n",
    "    \n",
    "    \n",
    "    def get_gene(self, size=4):\n",
    "        '''\n",
    "        Creates gene of the given size with a set number of decimal places\n",
    "        \n",
    "        Params:\n",
    "            size (int) the number of values within the gene\n",
    "        \n",
    "        Returns:\n",
    "            (np.array) a single gene\n",
    "        '''\n",
    "        \n",
    "#         create a random gene of the given size\n",
    "        gene = list(np.random.rand(size))\n",
    "\n",
    "        return list(gene)\n",
    "    \n",
    "    def get_population(self, size=3):\n",
    "        '''\n",
    "        Creates a population of the given size with random length genomes\n",
    "        \n",
    "        Params:\n",
    "            pop_size (int) the number random genomes to return\n",
    "        \n",
    "        Returns:\n",
    "            (np.array) a set of genomes\n",
    "        '''\n",
    "        \n",
    "        population = [\n",
    "            self.get_genome(\n",
    "            np.random.randint(1, self.__max_depth + 1)) for i in range(size)\n",
    "        ]\n",
    "\n",
    "        return population\n",
    "    \n",
    "    def map_gene(self, gene, spec):\n",
    "        \n",
    "        mapped_gene = {}\n",
    "        \n",
    "        for i, (k, v) in enumerate(spec.items()):\n",
    "\n",
    "            map_idx = int(math.floor(gene[i] * len(v)))\n",
    "            mapped_gene[k] = v[map_idx]\n",
    "        \n",
    "        return mapped_gene\n",
    "            \n",
    "    def map_genome(self, genome):\n",
    "        \n",
    "        mapped_genomes = {}\n",
    "        mapped_genomes['global_params'] = self.map_gene(genome[0], self.__global_spec)\n",
    "        \n",
    "        mapped_genomes['layer_params'] = {\n",
    "            i: self.map_gene(genome[i], self.__layer_spec) \n",
    "         for i in range(1, len(genome))\n",
    "        }\n",
    "        \n",
    "        return mapped_genomes\n",
    "    \n",
    "    def map_population(self, population):\n",
    "        \n",
    "        mapped_population = [self.map_genome(g) for g in population]\n",
    "        \n",
    "        return mapped_population "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e46ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Constructor:\n",
    "    '''\n",
    "    handles the stages of mapping a genome to the required set of \n",
    "    hyper-parameter values of various types. these are used to build and\n",
    "    compile a training ready model\n",
    "\n",
    "    parameters\n",
    "        shape (tuple) specifies the input shape of the data to be modelled eg (28, 28, 1) \n",
    "        output_size (int) the number of classes to be modelled eg 5\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, shape, output_size):\n",
    "        \n",
    "        self.__shape = shape\n",
    "        self.__output_size = output_size\n",
    "        \n",
    "    def build_model(self, parameters, metrics):\n",
    "        '''\n",
    "        builds a keras model of varying depth.\n",
    "        the depth is defined by the length of the layer_params\n",
    "        layers such as dropout and pooling are added if the parameters specifies true\n",
    "        each layer will have at least 1 conv2d and at most conv2d, maxpool, dropout\n",
    "        parameters are defined by the two sets passed in\n",
    "        \n",
    "        parameters:\n",
    "            parameters (dict) set of mapped parameters\n",
    "            \n",
    "        returns:\n",
    "            (keras.model) a compliled model ready for training\n",
    "        \n",
    "        '''\n",
    "        global_params = parameters['global_params']\n",
    "        layer_params = parameters['layer_params']\n",
    "        # used for the scaling of each filter size\n",
    "        prev_size = global_params['start_size']\n",
    "        # new empty model\n",
    "        model = keras.Sequential()\n",
    "    #     # set the input shape\n",
    "        model.add(keras.Input(shape=self.__shape))\n",
    "        \n",
    "        for i, key in enumerate(layer_params.keys()):\n",
    "            # extract the current layer's parameters to make code more readable\n",
    "            params = layer_params[key]\n",
    "            # calculate the layer size base on the previous size\n",
    "            layer_size = int(params['filter_size'] * prev_size)\n",
    "            \n",
    "            # CONV2D\n",
    "            model.add(\n",
    "                keras.layers.Conv2D(\n",
    "                    filters=layer_size, \n",
    "                    kernel_size=3, \n",
    "                    activation=params['filter_activation']\n",
    "                )\n",
    "            )\n",
    "            # MAX POOL\n",
    "            model.add(\n",
    "                keras.layers.MaxPooling2D(\n",
    "                    pool_size=params['max_pool_size']\n",
    "                )\n",
    "            )\n",
    "            # DROPOUT\n",
    "            if params['dropout_exists']:\n",
    "                # only add a droput layer if param = true\n",
    "                model.add(\n",
    "                    keras.layers.Dropout(\n",
    "                        rate=params['dropout_rate']\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            prev_size = layer_size\n",
    "            \n",
    "        # OUTPUT\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(self.__output_size, activation=\"softmax\"))      \n",
    "\n",
    "        # compile the model\n",
    "        model.compile(optimizer=global_params['optimizer'],\n",
    "                      loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=[metrics])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66fe61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(dict, name):\n",
    "    \n",
    "    filename = CURRENT_DIR\n",
    "    filename += '/ga_results/'\n",
    "    filename += f'{name}.json'\n",
    "\n",
    "    f = open(filename, \"w\")\n",
    "\n",
    "    json.dump(dict, f, indent = 6)\n",
    "\n",
    "    f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820dfe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evolution:\n",
    "    '''\n",
    "    Requires the Genome class using the static functions - instance not required\n",
    "    \n",
    "    Params:\n",
    "            probability (float) the rate of probability eg 1 is 100% and 0.5 is 50%\n",
    "            highest_is_fittest (bool) if true then higher values are considered fitter (eg accuracy)\n",
    "                          if false thenlower values are considered fitter (eg loss)\n",
    "            aggression (float) a higher number gives more weight to the fitter values giving a higher\n",
    "                                probability of these being chosen in the selection function\n",
    "            global_len (int) the length of the global gene in which each paramter represented by a single value\n",
    "            mutation_amount (float [0.0, 0.1]) the amount of mutation to be applied to any gene value \n",
    "    '''\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        probability=0.1,\n",
    "        highest_is_fittest=True, \n",
    "        aggression=2,\n",
    "        global_len=4,  \n",
    "        mutation_amount=0.1,\n",
    "        max_depth=5\n",
    "    ):\n",
    "        self.__probability = probability\n",
    "        self.__highest_is_fittest = highest_is_fittest \n",
    "        self.__aggression = aggression\n",
    "        self.__global_len = global_len \n",
    "        self.__mutation_amount = mutation_amount\n",
    "        self.__max_depth = max_depth\n",
    "\n",
    "    def probability_test(self):\n",
    "        '''\n",
    "        Returns true if the random number is below that of the rate parameter\n",
    "        This gives a probabilty test for any defined operations\n",
    "        \n",
    "        Returns:\n",
    "            (bool) true if the random number is less than the rate parameter\n",
    "        '''\n",
    "        return True if np.random.rand() < self.__probability else False\n",
    "\n",
    "    def select_fittest(self, fits):\n",
    "        '''\n",
    "        selects the fittest value from a list using the roulette method and returns \n",
    "        the index value of the original source list which can then be applied to a \n",
    "        list of genes or parameters if build using the same order\n",
    "        \n",
    "        parameters:\n",
    "            fits (array float) fitness values for a set of models\n",
    "\n",
    "        returns:\n",
    "            (int) the index value of the fittest value in the list\n",
    "        '''\n",
    "        # arbitary figure to ensure all significant values are integers\n",
    "        int_scale = 10000\n",
    "        \n",
    "        if self.__highest_is_fittest:\n",
    "            fits = (np.array(fits) * int_scale).astype(int)\n",
    "        else:\n",
    "#           invert the values in order to prioritize the lowest\n",
    "            fits = (1 /np.array(fits) * int_scale).astype(int)\n",
    "        # order the values such that the larger have a wider interval\n",
    "        cum_array = (np.cumsum(np.sort(fits)) * self.__aggression).astype(int)\n",
    "        # choose random int between zero and max of the cum array scaled by the exponent 1/aggression\n",
    "        random_idx = int((np.random.rand() ** (1/self.__aggression)) * cum_array[-1])\n",
    "#         find the corresponding index value within the cum array\n",
    "        idx = np.searchsorted(cum_array, random_idx, side=\"left\")\n",
    "\n",
    "        # Get the sorted indices of the array\n",
    "        sorted_indices = np.argsort(fits)\n",
    "    #     extrapolate back the index to that of the corresponding value in the fits array\n",
    "        res = sorted_indices[idx]\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def point_mutate(self, genome):\n",
    "        '''\n",
    "        Randomly mutates a gene or genes within the given set of genes. \n",
    "        The gene values are either increased or decreased depending on the random number -0.5 to 0.5. \n",
    "\n",
    "        Params:\n",
    "            genome (np.array) the set of genes to be mutated\n",
    "\n",
    "        Returns:\n",
    "            (list) the mutated set of genes\n",
    "        '''\n",
    "\n",
    "        for gene in genome:\n",
    "            for i, value in enumerate(gene):\n",
    "                gene[i] = self.mutate_gene_value(value)\n",
    "            \n",
    "        return genome\n",
    "    \n",
    "    def mutate_gene_value(self, gene_value):\n",
    "        \n",
    "        if self.probability_test():\n",
    "            \n",
    "            mutation = (np.random.rand() - 0.5) * self.__mutation_amount\n",
    "            gene_value = gene_value + mutation\n",
    "            # fix value in the interval [0.0, 0.99] \n",
    "            # to ensure the index remains within the spec values\n",
    "            gene_value = min(max(gene_value, 0), 0.99)\n",
    "            \n",
    "        return gene_value\n",
    "    \n",
    "    def shrink_mutate(self, genome):\n",
    "        '''\n",
    "        Probabilistically removes one gene to the genes set resulting in one less layer\n",
    "        \n",
    "        Params:\n",
    "            genome (np.array) set of genes to be mutated\n",
    "            \n",
    "        Returns:\n",
    "            (np.array) set of genes with len genes or genes - 1\n",
    "        '''\n",
    "        min_depth = 1\n",
    "#         ensure that the deep layer count is always >= 1\n",
    "\n",
    "        depth = self.get_genome_depth(genome)\n",
    "\n",
    "        if depth <= min_depth: return genome\n",
    "\n",
    "        if self.probability_test():\n",
    "            idx = np.random.randint(1, depth)\n",
    "            genome = genome[:-idx]\n",
    "\n",
    "        return genome\n",
    "    \n",
    "    def grow_mutate(self, genome):\n",
    "        '''\n",
    "        Probabilistically adds one gene to the genes set, resulting in another layer\n",
    "        \n",
    "        Params:\n",
    "            genome (np.array) set of genes to be mutated\n",
    "            \n",
    "        Returns:\n",
    "            (np.array) set of genes with len genes or genes + 1\n",
    "        '''\n",
    "        new_genome = []\n",
    "        layer_width = len(genome[-1])\n",
    "        depth = self.get_genome_depth(genome)\n",
    "        \n",
    "#       ensure layers never exceeds the maximum number of layers\n",
    "#       split at the global params index to get layers len\n",
    "        if depth >= self.__max_depth:\n",
    "               return genome\n",
    "\n",
    "        if self.probability_test():\n",
    "        # adds a new layer but not exceeding the max layers\n",
    "            new_gene = pn.get_gene(size=layer_width)\n",
    "            genome = genome + list([new_gene])\n",
    "                \n",
    "        return genome\n",
    "    \n",
    "    def crossover(self, genome_1, genome_2):\n",
    "        '''\n",
    "        Merges two genes at a random point to create a new \"child\" gene\n",
    "        \n",
    "        Params:\n",
    "            gene1 (np.array) single gene\n",
    "            gene2 (np.array) single gene\n",
    "            \n",
    "        Returns:\n",
    "            (np.array) set of genes with len genes or genes + 1\n",
    "        '''\n",
    "\n",
    "#         simplify the genomes such that the global can be divided\n",
    "        global_len = len(genome_1[0])\n",
    "        # parent 1\n",
    "        p1 = genome_1[0].copy()\n",
    "        p1.extend(genome_1[1:])\n",
    "        # parent 2\n",
    "        p2 = genome_2[0].copy()\n",
    "        p2.extend(genome_2[1:])\n",
    "#         use min() to ensure the index remains in the bounds \n",
    "#         of the smaller gene array and min_gene ensures at least one gene is crossed\n",
    "        min_gene = 1\n",
    "        min_len = len(p1)\n",
    "        split_idx = random.randint(1, random.randint(min_gene, min_len))\n",
    "        merge = p1[:split_idx] + p2[split_idx:]\n",
    "        # reshape into global and layer genes\n",
    "        child = [merge[:global_len]] + merge[global_len:]\n",
    "    \n",
    "        return child\n",
    "    \n",
    "    def get_genome_depth(self, genome):\n",
    "#         return the number of layers minus the global gene\n",
    "        return len(genome) - 1\n",
    "    \n",
    "    def get_next_generation(self, fits, pop):\n",
    "        '''\n",
    "        create a population of the size defined in the class parameters\n",
    "        \n",
    "        parameters:\n",
    "            fits (array) set of floats taken from each models evaluation performance\n",
    "            pop (2d array) the current population under evaluation\n",
    "        '''\n",
    "\n",
    "        next_generation = []\n",
    "        for i in range(len(fits)):\n",
    "\n",
    "#             find the index two fit parents\n",
    "            p1 = self.select_fittest(fits)\n",
    "            p2 = self.select_fittest(fits)\n",
    "\n",
    "#             get the genome of each parent\n",
    "            gn1 = pop[p1].copy()\n",
    "            gn2 = pop[p2].copy()\n",
    "            \n",
    "#             mate the parents\n",
    "            child = self.crossover(gn1, gn2)\n",
    "#             print(child)\n",
    "    #             apply the point mutation to the child\n",
    "            child = self.point_mutate(child)\n",
    "    #             grow, shrink or retain the depth using the probability applied within the functions\n",
    "            size_mutate = {\n",
    "                1: self.grow_mutate(child),\n",
    "                2: self.shrink_mutate(child),\n",
    "                3: child}\n",
    "            p = np.random.randint(1, 4)\n",
    "            child = size_mutate[p]\n",
    "\n",
    "            next_generation.append(child.copy())\n",
    "            \n",
    "        return next_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a4da925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GA_Optimizer:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        X, y, \n",
    "        model_builder=None,\n",
    "        population_class=None,\n",
    "        evolution_class=None,\n",
    "        validation_split=0.2, \n",
    "        callbacks=[],  \n",
    "        metrics='accuracy'\n",
    "    ):\n",
    "        self.__X = X\n",
    "        self.__y = y\n",
    "        self.__build_model = model_builder\n",
    "        self.__pn = population_class\n",
    "        self.__ev = evolution_class\n",
    "        self.__validation_split = validation_split\n",
    "        self.__callbacks = callbacks\n",
    "        self.__metrics = metrics\n",
    "        \n",
    "        # get the hi or low depending on the metric\n",
    "        self.__best_result = {\n",
    "            'accuracy': lambda x: max(x),\n",
    "            'val_accuracy': lambda x: max(x),\n",
    "            'loss': lambda x: min(x),\n",
    "            'val_loss': lambda x: min(x)\n",
    "        }\n",
    "        \n",
    "        # get the best index for the given metric\n",
    "        self.__best_idx = {\n",
    "            'accuracy': lambda x: np.argmax(x),\n",
    "            'val_accuracy': lambda x: np.argmax(x),\n",
    "            'loss': lambda x: np.argmin(x),\n",
    "            'val_loss': lambda x: np.argmin(x)\n",
    "        }\n",
    "        \n",
    "        assert model_builder\n",
    "        assert type(population_class) == Population\n",
    "        assert type(evolution_class) == Evolution\n",
    "    \n",
    "    def test_population(self, mapped_population=[], max_epochs=20, monitor_string=\"\"):\n",
    "        \n",
    "        generation_results = []\n",
    "        best_epochs = []\n",
    "        best_so_far = 0\n",
    "        \n",
    "        for idx, genome in enumerate(mapped_population):\n",
    "            # get batch size or default to 64\n",
    "            batch_size = genome['global_params'].get('batch_size', 64)\n",
    "            # build model with mapped genome\n",
    "            model = self.__build_model(genome, self.__metrics)\n",
    "            \n",
    "            # update screen status\n",
    "            clear_output()\n",
    "            print(f'{monitor_string}\\n')\n",
    "   \n",
    "            print(f'Genome   \\t| {idx + 1} of {len(mapped_population)}')\n",
    "            print(f'Depth \\t\\t| {len(genome) - 1}')\n",
    "            print(f'Batch size \\t| {batch_size}')\n",
    "            print(f'Best {self.__metrics}\\t| {best_so_far}\\n')\n",
    "            \n",
    "#           train the model using the given split\n",
    "            model.fit(\n",
    "                self.__X,\n",
    "                self.__y,\n",
    "                epochs=max_epochs, \n",
    "                validation_split=self.__validation_split, \n",
    "                batch_size=batch_size, \n",
    "                callbacks=[self.__callbacks],\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # get results\n",
    "            genome_results = model.history.history[self.__metrics]\n",
    "            # get the best in current genome\n",
    "            best_in_genome = self.__best_result[self.__metrics](genome_results)\n",
    "            generation_results.append(best_in_genome)\n",
    "            best_so_far = self.__best_result[self.__metrics](generation_results)\n",
    "            \n",
    "        # get the best the current generation\n",
    "        best_in_generation = self.__best_result[self.__metrics](generation_results)\n",
    "            \n",
    "        return generation_results, best_in_generation\n",
    "        \n",
    "    def evolve_generations(\n",
    "        self, \n",
    "        generations=5, \n",
    "        init_epochs=20, \n",
    "        pop_size=10, \n",
    "        epoch_increment=0,\n",
    "        test_name=\"test\"\n",
    "    ):\n",
    "        \n",
    "        # get initial population\n",
    "        epochs = init_epochs\n",
    "        pop = pn.get_population(pop_size)\n",
    "        mapped_population = pn.map_population(pop)\n",
    "        best_so_far = 0\n",
    "        \n",
    "        results_dict = {\n",
    "            'Best_parameters': [],\n",
    "            f'Best_{self.__metrics}': [],\n",
    "            f'Generation_{self.__metrics}': [],\n",
    "            'Best_so_far': [],\n",
    "            'Epochs' : []\n",
    "        }\n",
    "        \n",
    "        for generation in range(generations):\n",
    "             # update status on screen\n",
    "            monitor_string = f'Generation\\t| {generation + 1} of {generations}\\n'\n",
    "            monitor_string += f'Max epochs \\t| {epochs}\\n'\n",
    "            monitor_string += f'Best so far\\t| {best_so_far}\\n'\n",
    "            \n",
    "            print(f'{monitor_string}\\t')\n",
    "            # test the generation and get the results back\n",
    "            fits, best_result = self.test_population(\n",
    "                mapped_population, max_epochs=epochs,\n",
    "                monitor_string=monitor_string\n",
    "            )\n",
    "\n",
    "#             get the index of the fittest for the generation\n",
    "            fittest = self.__best_result[self.__metrics](fits)\n",
    "            fittest_idx = self.__best_idx[self.__metrics](fits)\n",
    "#             get the fittest of the current generation\n",
    "            best_genome = pop[fittest_idx]\n",
    "            best_params = mapped_population[fittest_idx]\n",
    "            \n",
    "            # get next generation of size n-1\n",
    "            # retain the fittest of the previous generation\n",
    "            pop = self.__ev.get_next_generation(fits, pop)[:-1]\n",
    "            pop.append(best_genome)\n",
    "            mapped_pop = self.__pn.map_population(pop)\n",
    "            \n",
    "            results_dict['Best_parameters'].append(best_params)\n",
    "            results_dict[f'Best_{self.__metrics}'].append(fittest) \n",
    "            results_dict[f'Generation_{self.__metrics}'].append(fits)\n",
    "            results_dict['Epochs'].append(epochs)\n",
    "            # update for status display\n",
    "            best_so_far = self.__best_result[\n",
    "                self.__metrics](results_dict[f'Best_{self.__metrics}']\n",
    "                               )\n",
    "            results_dict['Best_so_far'].append(best_so_far)\n",
    "            \n",
    "            # save each run in case of a crash\n",
    "            save_dict(results_dict, test_name)\n",
    "            # increase the number of epochs incrementally\n",
    "            epochs = epochs + epoch_increment\n",
    "            \n",
    "        return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0d436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation\t| 1 of 10\n",
      "Max epochs \t| 2\n",
      "Best so far\t| 0\n",
      "\n",
      "\n",
      "Genome   \t| 1 of 20\n",
      "Depth \t\t| 1\n",
      "Batch size \t| 192\n",
      "Best accuracy\t| 0\n",
      "\n",
      "Epoch 1/2\n",
      "\u001b[1m24/48\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 3s/step - accuracy: 0.3279 - loss: 56.9256"
     ]
    }
   ],
   "source": [
    "# population to create the inital population and mappings\n",
    "pn = Population(max_depth=4)   \n",
    "# new model constructor to handle the build and training of each genome\n",
    "mc = Model_Constructor(shape=dh.shape, output_size=5)\n",
    "# new evloution class to handle the genes\n",
    "ev = Evolution(probability=0.5, highest_is_fittest=True, mutation_amount=0.1, max_depth=4)\n",
    "\n",
    "# for the puprose of testing set the seed to the usual answer to life the universe and everything\n",
    "keras.utils.set_random_seed(42)\n",
    "# use the time so as to not inadvertantly overwrite previous tests\n",
    "test_name = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "X = dh.X_train\n",
    "y = dh.y_train\n",
    "\n",
    "optimizer = GA_Optimizer(\n",
    "    X=X, \n",
    "    y=y, \n",
    "    model_builder=mc.build_model, \n",
    "    population_class = pn,\n",
    "    evolution_class = ev,\n",
    "    metrics='accuracy'\n",
    ")\n",
    "\n",
    "results = optimizer.evolve_generations(\n",
    "    generations=10, \n",
    "    init_epochs=2, \n",
    "    pop_size=20, \n",
    "    epoch_increment=2,\n",
    "    test_name=test_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f376618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476367fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_population(\n",
    "    mapped_pop, \n",
    "    X, y, \n",
    "    max_epochs, \n",
    "    validation_split=0.2, \n",
    "    callbacks=[], \n",
    "    monitor_string=\"\", \n",
    "    metrics='accuracy'\n",
    "):\n",
    "    \n",
    "    best_results = []\n",
    "    best_epochs = []\n",
    "    best_so_far = float(\"inf\")\n",
    "\n",
    "    for i, genome in enumerate(mapped_pop):\n",
    "        # map the gene and build the model\n",
    "        model = mc.build_model(genome, metrics)\n",
    "        g = genome['global_params']\n",
    "        l = genome['layer_params']\n",
    "        # monitor metrics \n",
    "        depth = len(l.keys())\n",
    "        batch_size = g['batch_size']\n",
    "        \n",
    "        # process update to user\n",
    "        clear_output()\n",
    "        print(f'{monitor_string}')\n",
    "        print(f'Genome   \\t| {i + 1} of {len(mapped_pop)}')\n",
    "        print(f'Depth \\t\\t| {depth}')\n",
    "        print(f'Batch size \\t| {batch_size}\\n')\n",
    "        print(f'Best this gen  {best_so_far}\\n')\n",
    "        \n",
    "        # fit to the data \n",
    "        model.fit( \n",
    "                    X, \n",
    "                    y,\n",
    "                    epochs=max_epochs, \n",
    "                    validation_split=validation_split, \n",
    "                    batch_size=g['batch_size'], \n",
    "                    callbacks=[callbacks],\n",
    "                    verbose=1\n",
    "                )\n",
    "        \n",
    "        # get the training history\n",
    "        hist = model.history.history['loss']\n",
    "    #   store best fitness and the best epoch for survival of the fittest\n",
    "        best_result = min(hist)\n",
    "        # for monitoring during the test\n",
    "        best_so_far = min(best_so_far, best_result)\n",
    "        # for output for use in the Evolution class\n",
    "        best_epochs.append(len(hist))\n",
    "        best_results.append(best_result)\n",
    "        \n",
    "        \n",
    "    return best_results, best_epochs\n",
    "    \n",
    "\n",
    "def evolve_the_model(\n",
    "    X, y, generations, pop_size, start_epochs, epoch_factor, fitness_func, test_name):\n",
    "    \n",
    "    # create the callbacks\n",
    "    metrics = 'accuracy'\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(\n",
    "            monitor=metrics, \n",
    "            patience=3,\n",
    "            mode='auto'\n",
    "    )]\n",
    "    results = {}\n",
    "    file_path = 'ga_results.json'\n",
    "    \n",
    "    epochs=start_epochs\n",
    "    # for monitoring\n",
    "    best_so_far = float(\"inf\")\n",
    "    # get initial population of size n\n",
    "    pop = pn.get_population(size=pop_size)\n",
    "    mapped_pop = pn.map_population(pop)\n",
    "    \n",
    "    results = {\n",
    "        'Best_parameters': [],\n",
    "        'Best_fitness': [],\n",
    "        'Fitness_values': [],\n",
    "        'Best_so_far': [],\n",
    "        'Best_epochs' : []\n",
    "    }\n",
    "    # evolve for the number of generations\n",
    "    for generation in range(generations):\n",
    "        \n",
    "        monitor_string = f'Generation\\t| {generation + 1} of {generations}\\n'\n",
    "        monitor_string += f'Max epochs \\t| {epochs}\\n'\n",
    "        monitor_string += f'Best so far\\t| {best_so_far}\\n'\n",
    "        \n",
    "        fits, best_epochs = test_population(\n",
    "            mapped_pop=mapped_pop, \n",
    "            X=X, \n",
    "            y=y, \n",
    "            max_epochs=epochs, \n",
    "            validation_split=0.2, \n",
    "            callbacks=callbacks, \n",
    "            monitor_string=monitor_string,\n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        fittest = min(fits)\n",
    "        best_so_far = min(best_so_far, fittest)\n",
    "        best_genome = pop[np.argmin(fits)]\n",
    "        best_params = mapped_pop[np.argmin(fits)]\n",
    "\n",
    "        results['Best_parameters'].append(best_params)\n",
    "        results['Best_fitness'].append(fittest) \n",
    "        results['Fitness_values'].append(fits)\n",
    "        results['Best_epochs'].append(best_epochs)\n",
    "        results['Best_so_far'].append(best_so_far)\n",
    "        \n",
    "        # save each run in case of a crash\n",
    "        save_dict(results, test_name)\n",
    "        # increase the number of epochs incrementally\n",
    "        epochs = epochs + epoch_factor\n",
    "    # get next pop from the Evolution class of size n-1\n",
    "    # add back the fittest of the previous generation\n",
    "        pop = fitness_func(fits, pop)[:-1]\n",
    "        pop.append(best_genome)\n",
    "        mapped_pop = pn.map_population(pop)\n",
    "    return results\n",
    "    # can also reduce the population using the same idea - try as an experiment\n",
    "    \n",
    "    # also try using the early stopping as a bespoke in that if performance has\n",
    "    # not improved for n generations then end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# population to create the inital population and mappings\n",
    "pn = Population(max_depth=4)   \n",
    "# new model constructor to handle the build and training of each genome\n",
    "mc = Model_Constructor(shape=dh.shape, output_size=5)\n",
    "# new evloution class to handle the genes\n",
    "ev = Evolution(probability=0.5, highest_is_fittest=False, mutation_amount=0.1, max_depth=4)\n",
    "\n",
    "# for the puprose of testing set the seed to the usual answer to life the universe and everything\n",
    "keras.utils.set_random_seed(42)\n",
    "# use the time so as to not inadvertantly overwrite previous tests\n",
    "test_name = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "X = dh.X_train\n",
    "y = dh.y_train\n",
    "\n",
    "results = evolve_the_model(\n",
    "    X=X, y=y, \n",
    "    generations=10, \n",
    "    pop_size=10, \n",
    "    start_epochs=2, \n",
    "    epoch_factor=1, \n",
    "    fitness_func=ev.get_next_generation,\n",
    "    test_name=test_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild and train on entire set\n",
    "model = mc.build_model(g, l)\n",
    "vaidation_split = 0\n",
    "\n",
    "mc.train_model(\n",
    "    model, \n",
    "    X, \n",
    "    y, \n",
    "    epochs=max_epochs, \n",
    "    split=vaidation_split, \n",
    "    batch=g['batch_size']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fffad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA_Optimizer:\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.__X = X\n",
    "        self.__y = y\n",
    "        \n",
    "    def test_population(self):\n",
    "        pass\n",
    "    \n",
    "    def evolve_the_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results[1] = {'population':list(pop[0][4])}\n",
    "save_dict(results)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pn.get_population(pop_size=5)\n",
    "\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results, best_epochs = test_population(\n",
    "    population=pop, X=X, y=y, max_epochs=2, validation_split=0.2, callbacks=[], monitor_string=\"Test\"\n",
    ")\n",
    "print(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dda69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see twitter bookmark\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "with alive_bar() as bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804526a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(X, y, batch_size=g['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccdd736",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810212e",
   "metadata": {},
   "source": [
    "### Repeatability\n",
    "- The default initializer is random_glorot with a default seed=None.   \n",
    "- This, according to keras, produces a deterministic set of values https://keras.io/api/layers/initializers/  \n",
    "- \"Note that an initializer seeded with an integer or None (unseeded) will produce the same random values across multiple calls\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d82d70",
   "metadata": {},
   "source": [
    "### For the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e2016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop = pn.get_population(pop_size=5)\n",
    "genome = pop[0]\n",
    "pprint.pp(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4af61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_params, layer_params = mc.get_param_dict(genome)\n",
    "pprint.pp(global_params)\n",
    "pprint.pp(layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e742e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mc.build_model(global_params, layer_params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c9c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = [0.5,0.3,1,0.6,0.1]\n",
    "next_gen = ev.get_next_generation(fits, pop)\n",
    "print(f'Pop size: {[len(g) for g in pop]}')\n",
    "print(f'Next gen: {[len(g) for g in next_gen]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb44bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "child = ev.crossover(pop[0].copy(), pop[1].copy())\n",
    "child\n",
    "# ev.point_mutate(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "child = []\n",
    "c1 = pop[0][:idx].copy()\n",
    "c2 = pop[1][idx:].copy()\n",
    "print(f'{c1}\\n{c2}')\n",
    "\n",
    "child.extend(c1)\n",
    "child.extend(c2)\n",
    "print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# fits = [30, 20,10,10000,500,600,700,0.1]\n",
    "# fits = [0.4,0.3,0.6,0.1,0.7,0.2,0.18,0.1]\n",
    "fits = [1,2,3,4,5]\n",
    "# fits = best_results\n",
    "results = []\n",
    "pop = pn.get_population(pop_size=20)\n",
    "for i in range(1000):\n",
    "    res = ev.select_fittest(fits)\n",
    "    results.append(fits[res])\n",
    "    \n",
    "unique, counts = np.unique(results, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09886a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ev.select_fittest(best_results)\n",
    "print(best_results, best_results[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop = pn.get_population(pop_size=5)\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c15a76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop_test = pn.get_population(pop_size=10)\n",
    "c1 = pop_test[0]\n",
    "c2 = pop_test[1]\n",
    "print(f'C1{c1}\\n\\nC2{c2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728aed98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c0, idx = ev.crossover(c1, c2)\n",
    "print(f'idx: {idx}\\n\\nC0{c0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7053719",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mutated_genome = ev.grow_mutate(c1)\n",
    "mutated_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutated_genome = ev.shrink_mutate(c1)\n",
    "mutated_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = c1.copy()\n",
    "mutated_genome = ev.point_mutate(genome)\n",
    "mutated_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use in the model builder to assign a default in the case of a missing parameter\n",
    "d = {'test':100}\n",
    "d.get('t', 'default')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c349b2",
   "metadata": {},
   "source": [
    "# Redundant Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f95bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# class Model_Handler:\n",
    "    \n",
    "#     def __init__(self, shape, output_size, global_size, layer_size):\n",
    "#         self.__shape = shape\n",
    "#         self.__output_size = output_size\n",
    "#         # the size of the global parameters eg global_params = params[:global_size]\n",
    "#         self.__global_size = global_size\n",
    "#         # the size of each layer's parameters eg n arrays of width layer_size\n",
    "#         self.__layer_size = layer_size\n",
    "\n",
    "# #     def build_model(self, global_params, layer_params):\n",
    "        \n",
    "# #         # used for the scaling of each filter size\n",
    "# #         prev_size = global_params[2]\n",
    "# #         # new empty model\n",
    "# #         model = keras.Sequential()\n",
    "# #         # set the input shape\n",
    "# #         model.add(keras.Input(shape=self.__shape))\n",
    "# #         # using a reshaped layer parameter array loop each and apply\n",
    "# #         for size_scale, dropout, rate in layer_params:\n",
    "# #             layer_size = int(size_scale * prev_size)\n",
    "# #             # set the layer size as a multiple of the previous using the size_scale param\n",
    "# #             model.add(keras.layers.Conv2D(filters=layer_size, kernel_size=3, activation=\"relu\"))\n",
    "# #             model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "# #             # only add a droput layer if param = true\n",
    "# #             if dropout:\n",
    "# #                 model.add(keras.layers.Dropout(rate=rate))\n",
    "\n",
    "# #             prev_size = layer_size\n",
    "\n",
    "# #         # add the final layers of the model\n",
    "# #         model.add(keras.layers.Flatten())\n",
    "# #         model.add(keras.layers.Dense(self.__output_size, activation=\"softmax\"))      \n",
    "\n",
    "# #         # compile the model\n",
    "# #         model.compile(optimizer=\"rmsprop\",\n",
    "# #                       loss=\"sparse_categorical_crossentropy\",\n",
    "# #                       metrics=[\"accuracy\"])\n",
    "\n",
    "# #         return model\n",
    "    \n",
    "#     def train_model(model, X, y, epochs, split, batch, callbacks):\n",
    "#         model.fit(\n",
    "#         dh.X_train[:1000], \n",
    "#         dh.y_train[:1000], \n",
    "#         epochs=max_epochs, \n",
    "#         validation_split=val_split, \n",
    "#         batch_size=batch_size, \n",
    "#         callbacks=[callbacks]\n",
    "#     )\n",
    "        \n",
    "#     def test_population(self, population):\n",
    "#         # split into global and layer params\n",
    "#         global_params = params[:self.__global_size]\n",
    "#         layer_params = np.array(params[self.__global_size:]).reshape(self.__layer_shape)\n",
    "        \n",
    "#         for genome in population:\n",
    "#             print(genome)\n",
    "# #             model = self.build_model(global_params, layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2b8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# mh = Model_Handler(\n",
    "#     shape=(281, 362, 1), \n",
    "#     output_size=5, \n",
    "#     global_size=population.global_size, \n",
    "#     layer_shape=population.layer_shape\n",
    "# )\n",
    "# # model = mh.build_model(global_params, layer_params)\n",
    "# # model.summary()\n",
    "\n",
    "# mh.test_population(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# # set the params\n",
    "# max_epochs = 5\n",
    "# vaidation_split = 0.2\n",
    "# batch_size = 256\n",
    "\n",
    "# # create the callbacks\n",
    "# monitor = 'val_loss'\n",
    "# checkpoint_path = 'checkpoint_path.keras'\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(\n",
    "#         monitor=monitor, \n",
    "#         patience=3\n",
    "#     ),\n",
    "    \n",
    "# #     keras.callbacks.ModelCheckpoint(\n",
    "# #         filepath=checkpoint_path, \n",
    "# #         monitor=monitor, \n",
    "# #         save_best_only=True\n",
    "# #     )\n",
    "# ]\n",
    "\n",
    "# model.fit(\n",
    "#     dh.X_train[:1000], \n",
    "#     dh.y_train[:1000], \n",
    "#     epochs=max_epochs, \n",
    "#     validation_split=vaidation_split, \n",
    "#     batch_size=batch_size, \n",
    "#     callbacks=[callbacks]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# initializer = keras.initializers.Ones()\n",
    "# layer = keras.layers.Conv2D(filters=layer_size, kernel_size=3, activation=\"relu\", kernel_initializer=initializer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "ml3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
