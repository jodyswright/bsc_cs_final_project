{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f94d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env using Python 3.10.14\n",
    "# pip install notebook==5.7.5\n",
    "\n",
    "# the keras libraries\n",
    "# pip install tensorflow Version: 2.17.0\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras import models, layers\n",
    "\n",
    "# Version: 3.4.1\n",
    "from tensorflow import keras\n",
    "\n",
    "# pip install keras-tuner\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23edb2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use for splitting the test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for the creation of the cartesian product grid\n",
    "from itertools import product\n",
    "\n",
    "# for the timing of each test\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "7aa786f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4991e404",
   "metadata": {},
   "source": [
    "# Basic conv net to achieve statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f6f07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Handling:\n",
    "    '''\n",
    "    requirements:\n",
    "        math\n",
    "        numpy\n",
    "        train_test_split from sklearn.model_selection\n",
    "        \n",
    "    '''\n",
    "    def __init__(self, output_size=5, batch_size=128, ):\n",
    "        self.__shape = 0\n",
    "        self.__output_size = output_size\n",
    "        self.__length = 0\n",
    "        \n",
    "        \n",
    "    def load_data(self, label_path, data_path, split=0.2):\n",
    "        # load the images and labels\n",
    "        self.__labels = np.load(label_path)\n",
    "        self.__data = np.load(data_path)\n",
    "        self.__length = self.__labels.shape[0]\n",
    "        self.__shape = self.__data[1].shape\n",
    "        \n",
    "\n",
    "        print(\"Loaded files of size:\")\n",
    "        print(f\"Images: {self.__data.shape}\\nLabels: {self.__labels.shape}\")\n",
    "        \n",
    "    def split_data(self, split=0.2):\n",
    "        # split and shuffle the data and labels\n",
    "        self.__X_train, self.__X_test, self.__y_train, self.__y_test = train_test_split(\n",
    "            self.__data, self.__labels, test_size=split)\n",
    "        \n",
    "    \n",
    "    def run_tuner(timer, tuner, max_epochs=50, batch_size=64, callbacks=[])\n",
    "        SPLIT = 0.2\n",
    "        timer.start(test_name)\n",
    "\n",
    "        tuner.search(\n",
    "            self.__X_train, self.__y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=max_epochs,\n",
    "            validation_split=SPLIT,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        # get and view the best performing hyper parameter set\n",
    "        best_hps = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "        test_duration = timer.stop(best_hps.values)\n",
    "        best_hps.values\n",
    "\n",
    "    @property\n",
    "    def shape(self, ):\n",
    "        return self.__shape\n",
    "    \n",
    "    @property\n",
    "    def output_size(self, ):\n",
    "        return self.__output_size\n",
    "    \n",
    "    @property\n",
    "    def X_train(self, ):\n",
    "        return self.__X_train\n",
    "    \n",
    "    @property\n",
    "    def y_train(self, ):\n",
    "        return self.__y_train\n",
    "    \n",
    "    @property\n",
    "    def X_test(self, ):\n",
    "        return self.__X_test\n",
    "    \n",
    "    @property\n",
    "    def y_test(self, ):\n",
    "        return self.__y_test\n",
    "    \n",
    "    @property\n",
    "    def length(self, ):\n",
    "        return self.__length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39055730",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = Data_Handling()\n",
    "\n",
    "label_path = 'mitdb_labels_reduced.npy'\n",
    "data_path = 'mitdb_data_reduced.npy'\n",
    "\n",
    "dh.load_data(label_path=label_path, data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "872d62db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11352, 281, 362, 1) (2838, 281, 362, 1)\n"
     ]
    }
   ],
   "source": [
    "dh.split_data(split=0.2)\n",
    "print(dh.X_train.shape, dh.X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e0e6dd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# must prefix keras. unlike in the book\n",
    "def build_basic_model(shape, output_size, callbacks):\n",
    "    \n",
    "    inputs = keras.Input(shape=shape)   \n",
    "    x = keras.layers.Conv2D(filters=2, kernel_size=3, activation=\"relu\")(inputs) \n",
    "    x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    \n",
    "    outputs = keras.layers.Dense(output_size, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "975d1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the params\n",
    "max_epochs = 50\n",
    "vaidation_split = 0.2\n",
    "batch_size = 256\n",
    "\n",
    "# create the callbacks\n",
    "monitor = 'val_loss'\n",
    "checkpoint_path = 'checkpoint_path.keras'\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=monitor, \n",
    "        patience=3\n",
    "    ),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        monitor=monitor, \n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "32ec6a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 599ms/step - accuracy: 0.3284 - loss: 3542.2876 - val_accuracy: 0.6984 - val_loss: 289.1055\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 587ms/step - accuracy: 0.7509 - loss: 164.1139 - val_accuracy: 0.9005 - val_loss: 28.0742\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 592ms/step - accuracy: 0.8614 - loss: 70.9357 - val_accuracy: 0.9229 - val_loss: 14.7922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x320f0b790>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build fresh model\n",
    "basic_model = build_basic_model(dh.shape, dh.output_size, callbacks)\n",
    "\n",
    "# fit to the taining data\n",
    "basic_model.fit(\n",
    "    dh.X_train, \n",
    "    dh.y_train, \n",
    "    epochs=max_epochs, \n",
    "    validation_split=vaidation_split, \n",
    "    batch_size=batch_size, \n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fb153e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 538ms/step - accuracy: 0.3114 - loss: 8101.0479\n",
      "Epoch 2/3\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 535ms/step - accuracy: 0.4480 - loss: 1806.6357\n",
      "Epoch 3/3\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 537ms/step - accuracy: 0.7604 - loss: 292.8893\n"
     ]
    }
   ],
   "source": [
    "# using the epoch as per the early stopping callback above\n",
    "val_loss_history = basic_model.history.history['val_loss']\n",
    "# get the index of the lowest recorded loss function (+ 1 to account for 0 idx)\n",
    "best_epoch = np.argmin(val_loss_history) + 1\n",
    "\n",
    "\n",
    "# build and train a fresh model for evaluation\n",
    "basic_test_model = build_basic_model(dh.shape, dh.output_size, callbacks)\n",
    "# fit model on the entire training set by removing the validation_split param\n",
    "basic_model_history = basic_test_model.fit(\n",
    "    dh.X_train, \n",
    "    dh.y_train, \n",
    "    epochs=best_epoch, \n",
    "    batch_size=batch_size, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a72a0d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - accuracy: 0.9228 - loss: 0.4049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43242478370666504, 0.9221282601356506]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate performance on the unseen test data to see whether the basic model can beat \n",
    "# a the statistical significance calculated in the workbook [WORKBOOK]\n",
    "basic_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = basic_model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.argmax(pred, axis = 1)[:5] \n",
    "r = y_test[:5]\n",
    "print(p,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55041e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ed097",
   "metadata": {},
   "source": [
    "## Grid search using keras library functinon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8e82924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperModel(kt.HyperModel):\n",
    "    \n",
    "    def __init__(self, num_classes, shape, filter_step=16, lr_step=0.1 ):\n",
    "\n",
    "            self.__num_classes = num_classes\n",
    "            self.__shape = shape\n",
    "            self.__filter_step = filter_step\n",
    "            self.__lr_step = lr_step\n",
    "            \n",
    "    def build(self, hp):\n",
    "\n",
    "        filters_1 = hp.Int(name=\"filters_1\", min_value=16, max_value=32, step=self.__filter_step) \n",
    "        filters_2 = hp.Int(name=\"filters_2\", min_value=filters_1, max_value=64, step=self.__filter_step)\n",
    "        # allows a zero setting \n",
    "        rate_1 = hp.Float(name=\"rate_1\", min_value=0, max_value=0.5, step=self.__lr_step)\n",
    "        \n",
    "        inputs = keras.Input(shape=self.__shape)\n",
    "        x = keras.layers.Conv2D(filters=filters_1, kernel_size=3, activation=\"relu\")(inputs) \n",
    "        x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "        x = keras.layers.Dropout(rate=rate_1)(x)\n",
    "        x = keras.layers.Conv2D(filters=filters_2, kernel_size=3, activation=\"relu\")(x) \n",
    "        x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "        x = keras.layers.Flatten()(x)\n",
    "        \n",
    "        outputs = keras.layers.Dense(self.__num_classes, activation=\"softmax\")(x)\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0718148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tuner_Timer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__start = None\n",
    "        self.__end = None\n",
    "        self.__duration = None\n",
    "#         self.__results = {}\n",
    "#         self.__tuners = []\n",
    "#         self.__common_params = common_params\n",
    "#         self.__callbacks = []\n",
    "        \n",
    "    def add_tuner(self, tuner):\n",
    "        self.__tuners.append(tuner)\n",
    "        \n",
    "    def start(self):\n",
    "        '''\n",
    "        start the timer \n",
    "        '''\n",
    "        self.__start = time.time()\n",
    "        \n",
    "    def stop(self):\n",
    "        '''\n",
    "        stop the timer and format the duration\n",
    "        '''\n",
    "        self.__end = time.time()\n",
    "        self.__duration = self.__end - self.__start\n",
    "        duration_string = time.strftime('%H:%M:%S', time.gmtime(self.__duration))\n",
    "\n",
    "        return duration_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "9c3dcaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_result(results_dict, results, tuner):\n",
    "\n",
    "    if tuner.project_name in results_dict.keys():\n",
    "        \n",
    "        results_dict[tuner.project_name].update(results)\n",
    "#         print(results)\n",
    "    else:\n",
    "        results_dict[tuner.project_name] = results\n",
    "        \n",
    "    #save the current result to file\n",
    "    f = open(f\"{tuner.directory}/results.json\", \"w\")\n",
    "\n",
    "    json.dump(results, f, indent = 6)\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "ded3b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tuner(timer, tuner, batch_size, max_epochs, callbacks):\n",
    "        '''\n",
    "        run a given tuner saving the best parameter configuration to a timer object\n",
    "        along with the total duration of the optimizer's run\n",
    "\n",
    "        params:\n",
    "            timer (Tuner_Timer) the timer used for recording results\n",
    "            tuner (keras.Tuner) the current tuner under test \n",
    "            batch_size (int) batch for training \n",
    "            max_epochs (int) the maximum number of epochs to run if not stopped by early stopping\n",
    "            callbacks (keras.callbacks) for early stopping\n",
    "        '''\n",
    "        # start timer\n",
    "        timer.start()\n",
    "        # the tuner will save results to the directory specified in the tuner constructor\n",
    "        tuner.search(\n",
    "            dh.X_train[:1000], dh.y_train[:1000],\n",
    "            batch_size=batch_size,\n",
    "            epochs=max_epochs,\n",
    "            validation_split=0.2,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "\n",
    "        # get the best performing hyper parameter set\n",
    "        best_hps = tuner.get_best_hyperparameters()[0].values\n",
    "        # stop timing and get the duration\n",
    "        test_duration = timer.stop()\n",
    "        \n",
    "        return {'duration':test_duration, 'best_params':best_hps}\n",
    "#         return {tuner.tuner_id:{'duration':'00:00:10', 'best_params':{'1':100, '2':200}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "50947227",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = HyperModel(num_classes=dh.output_size, shape=dh.shape, filter_step=16)\n",
    "\n",
    "directory = \"start-11-08\"\n",
    "\n",
    "common_params = {\n",
    "    'hypermodel': hypermodel, \n",
    "    'objective': \"val_accuracy\", \n",
    "    'executions_per_trial':1,\n",
    "    'directory':directory,\n",
    "    'tuner_id':tuner_id,\n",
    "    'overwrite':False,\n",
    "}\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "7fb77c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 16s]\n",
      "val_accuracy: 0.5099999904632568\n",
      "\n",
      "Best val_accuracy So Far: 0.6899999976158142\n",
      "Total elapsed time: 00h 02m 17s\n"
     ]
    }
   ],
   "source": [
    "# RANDOM\n",
    "tuners.append(kt.RandomSearch(project_name='random', max_trials=5, **common_params))\n",
    "\n",
    "best_result = run_tuner(timer, tuners[0], batch_size, max_epochs, callbacks)\n",
    "# add best params to result dict and save current dict to file\n",
    "save_best_result(best_results, best_result, tuners[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcceeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERBAND\n",
    "tuners.append(kt.Hyperband(project_name='hyperband', factor=3, hyperband_iterations=1, **common_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "e57f1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAYES\n",
    "tuners.append(kt.BayesianOptimization(project_name='bayes', **common_params))\n",
    "\n",
    "# GRID\n",
    "tuners.append(kt.GridSearch(project_name='grid', **common_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "f2fc846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "max_epochs = 2\n",
    "\n",
    "timer = Tuner_Timer()\n",
    "best_results = {}\n",
    "tuners = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55979b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all optimizers\n",
    "for tuner in tuners:\n",
    "    \n",
    "    # run the optimizer\n",
    "    best_result = run_tuner(timer, tuner, batch_size, max_epochs, callbacks)\n",
    "    # add best params to result dict and save current dict to file\n",
    "    save_best_result(best_results, best_result, tuner)\n",
    "    \n",
    "    loss, accuracy, best_epoch = retrain_and_evaluate(tuners[0])\n",
    "    \n",
    "    best_results[tuners[0].project_name]['loss'] = loss\n",
    "    best_results[tuners[0].project_name]['accuracy'] = accuracy\n",
    "    best_results[tuners[0].project_name]['best_epoch'] = best_epoch\n",
    "    \n",
    "    print(f'Loss: {loss}\\tAccuracy: {accuracy}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "77d28829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random': {'duration': '00:02:17',\n",
       "  'best_params': {'filters_1': 16,\n",
       "   'filters_2': 32,\n",
       "   'rate_1': 0.2,\n",
       "   'learning_rate': 0.01}}}"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "dde39636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in start-11-08/random\n",
      "Showing 1 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "filters_1: 16\n",
      "filters_2: 32\n",
      "rate_1: 0.2\n",
      "learning_rate: 0.01\n",
      "Score: 0.6899999976158142\n"
     ]
    }
   ],
   "source": [
    "tuners[0].results_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "a381526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_and_evaluate(tuner):\n",
    "    # get the object hp to rebuild a fresh model\n",
    "    best_hps = tuners[0].get_best_hyperparameters()[0]\n",
    "    # build a fresh model for retraining in order to find the point of overfitting\n",
    "    model = hypermodel.build(best_hps)\n",
    "    print('Finding best epoch')\n",
    "    model.fit(dh.X_train[:1000], dh.y_train[:1000],\n",
    "                batch_size=batch_size,\n",
    "                epochs=max_epochs,\n",
    "                validation_split=0.2,\n",
    "                callbacks=callbacks,)\n",
    "\n",
    "    # find best epoch since there seems no way to find this in the tuner\n",
    "    best_epoch = np.argmin(model.history.history['val_loss'])\n",
    "    # rebuild fresh model\n",
    "    print(f'\\nRetraining to best epoch: {best_epoch}')\n",
    "    model = hypermodel.build(best_hps)\n",
    "    # reterain on the entire set for the best epoch\n",
    "    model.fit(dh.X_train[:1000], dh.y_train[:1000],\n",
    "                batch_size=batch_size,\n",
    "                epochs=best_epoch,)\n",
    "    \n",
    "    print('\\nEvaluating model')\n",
    "    loss, accuracy = model.evaluate(dh.X_test[:1000], dh.y_test[:1000])\n",
    "    return loss, accuracy, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "708aad10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best epoch\n",
      "Epoch 1/2\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.2469 - loss: 29561.8145 - val_accuracy: 0.5100 - val_loss: 84.5610\n",
      "Epoch 2/2\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.2824 - loss: 239.8521 - val_accuracy: 0.5100 - val_loss: 2.3600\n",
      "\n",
      "Retraining to best epoch: 1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.2930 - loss: 98111.7891 \n",
      "\n",
      "Evaluating model\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5018 - loss: 1.5688\n",
      "Loss: 1.5684082508087158\tAccuracy: 0.4959999918937683\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, best_epoch = retrain_and_evaluate(tuners[0])\n",
    "best_results[tuners[0].project_name]['loss'] = loss\n",
    "best_results[tuners[0].project_name]['accuracy'] = accuracy\n",
    "best_results[tuners[0].project_name]['best_epoch'] = best_epoch\n",
    "print(f'Loss: {loss}\\tAccuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "6afd7cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random': {'duration': '00:02:17',\n",
       "  'best_params': {'filters_1': 16,\n",
       "   'filters_2': 32,\n",
       "   'rate_1': 0.2,\n",
       "   'learning_rate': 0.01},\n",
       "  'loss': 1.5684082508087158,\n",
       "  'accuracy': 0.4959999918937683,\n",
       "  'best_epoch': 1}}"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_and_evaluate(params):\n",
    "    '''\n",
    "    rebuild a fresh model and retrain on the entire dataset\n",
    "    \n",
    "    # model =  build(params)\n",
    "    # model.fit( ... )\n",
    "    # model.evaluate( ... )\n",
    "    return:\n",
    "        evaluation metric\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d31e378",
   "metadata": {},
   "source": [
    "[cite]  \n",
    "The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. Hyperband determines the number of models to train in a bracket by computing 1 + logfactor(max_epochs) and rounding it up to the nearest integer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af7c5a",
   "metadata": {},
   "source": [
    "## Redundant code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0e6d14e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'hyperband': {'r1': 100, 'r2': 150}, 'bayes': {'r1': 100, 'r2': 150}},\n",
       " 1: {'hyperband': {'r1': 100, 'r2': 150}, 'bayes': {'r1': 100, 'r2': 150}},\n",
       " 2: {'hyperband': {'r1': 999, 'r2': 999}}}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "     0:\n",
    "      {'hyperband':\n",
    "       {'r1':100,'r2':150},\n",
    "      'bayes':\n",
    "       {'r1':100,'r2':150}\n",
    "      },\n",
    "      1:\n",
    "      {'hyperband':\n",
    "       {'r1':100,'r2':150},\n",
    "      'bayes':\n",
    "       {'r1':100,'r2':150}\n",
    "      }\n",
    "     }\n",
    "    \n",
    "d[2] = {\"hyperband\":{}}\n",
    "d[2]['hyperband'] = {'r1':999,'r2':999}\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f07064",
   "metadata": {},
   "source": [
    "### Results\n",
    "Error \"BiasGrad requires tensor size <= int32 max\" with batch 256  \n",
    "https://stackoverflow.com/questions/60414562/how-to-solve-the-biasgrad-requires-tensor-size-int32-max-invalidargumenterr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622febbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "ml3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
