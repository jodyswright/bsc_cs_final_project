{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5352cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# lib for handling the data at physionet\n",
    "import wfdb\n",
    "# for use with utility functions in wfdb\n",
    "from wfdb import processing\n",
    "\n",
    "# for creating a buffer to store the image arrays\n",
    "from io import BytesIO\n",
    "# for creating the image buffer\n",
    "from PIL import Image\n",
    "# creates the image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86876750",
   "metadata": {},
   "source": [
    "## Convert data to image arrays\n",
    "Steps:  \n",
    "- load all data excluding the normal which is causes a large imbalance in the data. do this by editing the supergroup_classes dict\n",
    "- select record 1 and load only the normal class data from there. Again done by editing the supergroup_classes dict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be7dfbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class process_data:\n",
    "    '''\n",
    "    Main class to handle each record's processing in order to return all\n",
    "    records as one single array of labels and heartbeats\n",
    "    \n",
    "    Requirements:\n",
    "        wfdb\n",
    "        wfdb.processing\n",
    "        numpy\n",
    "        BytesIO\n",
    "        matplotlib.pyplot\n",
    "    \n",
    "    wfdb library https://wfdb.readthedocs.io/en/latest/io.html#wfdb-annotations\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.__image_arrays = []\n",
    "        self.__label_strings = []\n",
    "        \n",
    "    def create_img_arrays(self, supergroup_classes, record_names):\n",
    "        '''\n",
    "        Load each record and create the imgage arrays. \n",
    "        \n",
    "        parameters:\n",
    "            supergroup_classes (dict) classes used to group the annotations\n",
    "            record_names (list) list of the record names from physionet\n",
    "        '''\n",
    "        \n",
    "        print(f\"|Total records: {len(record_names)}\")\n",
    "        print(f\"|Classes: {set(supergroup_classes.values())}\")\n",
    "        \n",
    "        # skip odd sized and empty arrays at the start and end\n",
    "        # to prevent a jagged array being attempted\n",
    "        start = 2\n",
    "        end = -1\n",
    "\n",
    "        for record_name in record_names:\n",
    "            # get signal and label data\n",
    "            print(f\"|Loading: {record_name} \", end=\"\")\n",
    "            signal, fields, annotations = self.load_data(record_name=record_name)\n",
    "            # get the mean heartrate for the record\n",
    "            mean = self.get_mean_heartrate(signal, fields)\n",
    "            print(f\"|Mean HR: {mean:.2f} \", end=\"\")\n",
    "\n",
    "            # split the heartbeats and get labels\n",
    "            beats, labels = self.separate_hearbeats(signal, annotations, mean, supergroup_classes)\n",
    "            # confirm a matching set of labels and beats\n",
    "            assert len(beats) == len(labels), \"Mismatch in labels and images\"\n",
    "\n",
    "            self.__label_strings.extend(labels[start: end])\n",
    "            print(f\"|Len beats: {len(beats)}\\t, labels: {len(labels)}\\t|\")\n",
    "\n",
    "            imgs = np.array([self.get_image_array(beat) for beat in beats[start: end]])\n",
    "            self.__image_arrays.extend(imgs)\n",
    "        \n",
    "    @property\n",
    "    def image_arrays(self):\n",
    "        return np.array(self.__image_arrays)\n",
    "    \n",
    "    @property\n",
    "    def label_strings(self):\n",
    "        return np.array(self.__label_strings)\n",
    "\n",
    "    # get the data\n",
    "    def load_data(self, record_name, path='mitdb', extension='atr'):\n",
    "        '''\n",
    "        Using the wfdb library provided by physionet, load a single patient's ECG data along with the \n",
    "        metadata and cardioligist's annotations.\n",
    "\n",
    "        requirements:\n",
    "            wfdb\n",
    "            numpy\n",
    "\n",
    "        params:\n",
    "            record_name (str) the record name as per physionet database\n",
    "                these can be found by searching using wfdb.io.get_record_list(db_dir, , records='all')\n",
    "            path (str) the path on physionet eg 'mitdb' search using wfdb.io.get_dbs()\n",
    "            extension (str) the file extension of the annotation file eg 'atr'\n",
    "\n",
    "        returns:\n",
    "            signal (np.array) the signal data of n channels\n",
    "            fields (dict) a dict containing the meta data for the singnal such as sampling rate\n",
    "            annotations (np.array) a 2d array containing the labels and their respective position at sample number n\n",
    "        '''\n",
    "        # get the 2d signal array from channel 0 which is the p signal\n",
    "        signal, fields = wfdb.rdsamp(record_name=record_name, pn_dir=path, channels=[0])\n",
    "        # the annotations\n",
    "        annotations = wfdb.rdann(record_name=record_name, extension=extension, pn_dir=path)\n",
    "\n",
    "        return signal, fields, annotations\n",
    "\n",
    "    def get_mean_heartrate(self, signal, fields):\n",
    "        '''\n",
    "        Calculates the mean distance in samples between each QRS peak. \n",
    "        The QRS peaks are first located and then used to calculate the heart rate in beats per minute. \n",
    "        The distance in samples is then calculated by dividing into 60\n",
    "\n",
    "        requirements:\n",
    "            wfdb.processing\n",
    "            wfdb\n",
    "            numpy\n",
    "\n",
    "        params:\n",
    "            (np.array) the signal data of n channels\n",
    "            (dict) a dict containing the meta data for the singnal such as sampling rate\n",
    "\n",
    "        returns:\n",
    "            mean (float) the mean heart rate\n",
    "\n",
    "        '''\n",
    "        # find the qrs locations for computing the HR\n",
    "        xqrs = processing.XQRS(sig=signal[:,0], fs=fields['fs'])\n",
    "        xqrs.detect(verbose=False)\n",
    "        # get the heart rate at each QRS\n",
    "        hr = wfdb.processing.compute_hr(sig_len=fields['sig_len'], qrs_inds=xqrs.qrs_inds, fs=fields['fs'])\n",
    "        # the mean length in samples of the heart rate which ought to correspond to the RR length\n",
    "        mean = (np.nanmean(hr) / 60) * fields['fs']\n",
    "\n",
    "        return mean\n",
    "\n",
    "    def get_image_array(data):\n",
    "        '''\n",
    "        Convert to an image array of size 362, 281 to capture each sample once\n",
    "        and reduce to a single color channel to reduce complexity\n",
    "\n",
    "        requirements:\n",
    "            BytesIO\n",
    "            matplotlib.pyplot\n",
    "\n",
    "        params:\n",
    "            data (np.array) raw data from a single heartbeat\n",
    "\n",
    "        returns:\n",
    "            img_array (np.array) a 2d array containing a single single hearbeat's pattern\n",
    "        '''\n",
    "        # shape plot to match the x dim to reduce data size\n",
    "        # the y is based on the default aspect ratio since the heights can vary\n",
    "        dpi = 100\n",
    "    #     aspect = 1.333 # that used by defaut with the plot\n",
    "        width = 362\n",
    "        height = 281\n",
    "\n",
    "        # create plot\n",
    "        fig, ax = plt.subplots(figsize=(width/dpi, height/dpi))\n",
    "        plt.plot(data)\n",
    "        # remove unecessary information\n",
    "        plt.axis('off')\n",
    "\n",
    "        # save plot to a buffer for export\n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "\n",
    "        # close fig to free memory \n",
    "        plt.close(fig)\n",
    "\n",
    "        # Convert the image to a numpy array and save only one colour channel\n",
    "        # color is of no use since the images have been recreated from x, y data only\n",
    "        img_array = np.array(Image.open(buf))[:, :, 0:1]\n",
    "    #     print(img_array.shape)\n",
    "        # Close the buffer\n",
    "        buf.close()\n",
    "\n",
    "        return img_array\n",
    "\n",
    "    def separate_hearbeats(self, signal, annotations, mean_rate, supergroup_classes):\n",
    "        '''\n",
    "        Takes an ecg record and separates into individual beats with the QRS peak taking\n",
    "        the centre position in the frame. \n",
    "        Each beat has an annotation which are grouped here into 5 main supergroups.\n",
    "\n",
    "        params:\n",
    "            signal (np.array) the raw ecg signal data to be split\n",
    "            annotations (np.array) the single letter annotations for each QRS\n",
    "            mean_rate (float) the mean heart rate of a given series\n",
    "                this is used to create a window either side of the annotation location\n",
    "                from which to slice each sample\n",
    "            supergroup_classes (dict) classes to include in the result\n",
    "\n",
    "        returns:\n",
    "            signal_images (np.array) a set of 2d images each representing a single hearbeat\n",
    "            labels (np.array) the grouped label strings of 1 char len each\n",
    "        '''\n",
    "        signal_images = []\n",
    "        labels = []\n",
    "\n",
    "        # create a frame in samples to slice either side of the peak scaled to 2nd std\n",
    "        scale_factor = 0.786\n",
    "        # scale to ensure shorter beats in arrhythmias do not contain more than one QRS\n",
    "        frame = int((mean_rate * scale_factor) / 2) \n",
    "        # loop through and get each not matching the filter\n",
    "        signal = np.array(signal[:, 0])\n",
    "        for i, pos in enumerate(annotations.sample):\n",
    "    #         if annotations.symbol[i] != filters:\n",
    "            if annotations.symbol[i] in supergroup_classes:\n",
    "                signal_images.append(signal[pos - frame: pos + frame])\n",
    "    #             labels.extend(annotations.symbol[i])\n",
    "                #s = super_group_classes[annotations.symbol[i]]\n",
    "    #             print(s)\n",
    "                labels.append(supergroup_classes[annotations.symbol[i]])\n",
    "\n",
    "        return signal_images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path within physionet\n",
    "path='mitdb'\n",
    "# filename to save data to file\n",
    "file_name = path\n",
    "# get a full list of the record names from physionet\n",
    "record_names = wfdb.io.get_record_list(db_dir=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e292670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to generalize the classes into supergroups\n",
    "supergroups_exc_n = {\n",
    "    # superventricular\n",
    "    'A': 0, 'a': 0, 'J': 0, 'S': 0, 'e': 0, 'j': 0, 'n': 0,\n",
    "    # ventricular\n",
    "    'V': 1, 'r': 1, 'E': 1,\n",
    "    # fusion\n",
    "    'F': 2, 'f': 2,\n",
    "    # unknown\n",
    "    'Q': 3, '?': 3,\n",
    "}\n",
    "\n",
    "supergroups_inc_n = {\n",
    "    # normal\n",
    "    'N': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d661a6cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Total records: 48\n",
      "|Classes: {0, 1, 2, 3}\n",
      "|Loading: 100 |Mean HR: 454.73 |Len beats: 34\t, labels: 34\t|\n",
      "|Loading: 101 |Mean HR: 373.63 |Len beats: 5\t, labels: 5\t|\n",
      "|Loading: 102 |Mean HR: 436.42 |Len beats: 60\t, labels: 60\t|\n",
      "|Loading: 103 |Mean HR: 415.58 |Len beats: 2\t, labels: 2\t|\n",
      "|Loading: 104 |Mean HR: 449.30 |Len beats: 686\t, labels: 686\t|\n",
      "|Loading: 105 |Mean HR: 527.60 |Len beats: 46\t, labels: 46\t|\n",
      "|Loading: 106 |Mean HR: 458.34 |Len beats: 520\t, labels: 520\t|\n",
      "|Loading: 107 |Mean HR: 426.55 |Len beats: 59\t, labels: 59\t|\n",
      "|Loading: 108 |Mean HR: 453.44 |Len beats: 24\t, labels: 24\t|\n",
      "|Loading: 109 |Mean HR: 505.93 |Len beats: 40\t, labels: 40\t|\n",
      "|Loading: 111 |Mean HR: 423.90 |Len beats: 1\t, labels: 1\t|\n",
      "|Loading: 112 |Mean HR: 506.43 |Len beats: 2\t, labels: 2\t|\n",
      "|Loading: 113 |Mean HR: 360.02 |Len beats: 6\t, labels: 6\t|\n",
      "|Loading: 114 |Mean HR: 380.71 |Len beats: 59\t, labels: 59\t|\n",
      "|Loading: 115 |Mean HR: 390.46 |Len beats: 0\t, labels: 0\t|\n",
      "|Loading: 116 |Mean HR: 488.64 |Len beats: 110\t, labels: 110\t|\n",
      "|Loading: 117 |Mean HR: 306.25 |Len beats: 1\t, labels: 1\t|\n",
      "|Loading: 118 |Mean HR: 458.87 |Len beats: 112\t, labels: 112\t|\n",
      "|Loading: 119 |Mean HR: 446.32 |Len beats: 444\t, labels: 444\t|\n",
      "|Loading: 121 |Mean HR: 371.66 |Len beats: 2\t, labels: 2\t|\n",
      "|Loading: 122 |Mean HR: 494.25 |Len beats: 0\t, labels: 0\t|\n",
      "|Loading: 123 |Mean HR: 303.15 |Len beats: 3\t, labels: 3\t|\n",
      "|Loading: 124 |Mean HR: 322.29 |Len beats: 88\t, labels: 88\t|\n",
      "|Loading: 200 |Mean HR: 558.69 |Len beats: 858\t, labels: 858\t|\n",
      "|Loading: 201 |Mean HR: 402.33 |Len beats: 338\t, labels: 338\t|\n",
      "|Loading: 202 |Mean HR: 441.13 |Len beats: 75\t, labels: 75\t|\n",
      "|Loading: 203 |Mean HR: 651.05 |Len beats: 451\t, labels: 451\t|\n",
      "|Loading: 205 |Mean HR: 533.35 |Len beats: 85\t, labels: 85\t|\n",
      "|Loading: 207 |Mean HR: 456.28 |Len beats: 317\t, labels: 317\t|\n",
      "|Loading: 208 |Mean HR: 581.80 |Len beats: 1369\t, labels: 1369\t|\n",
      "|Loading: 209 |Mean HR: 603.16 |Len beats: 384\t, labels: 384\t|\n",
      "|Loading: 210 |Mean HR: 541.99 |Len beats: 227\t, labels: 227\t|\n",
      "|Loading: 212 |Mean HR: 548.38 |Len beats: 0\t, labels: 0\t|\n",
      "|Loading: 213 |Mean HR: 651.27 |Len beats: 610\t, labels: 610\t|\n",
      "|Loading: 214 |Mean HR: 489.75 |Len beats: 259\t, labels: 259\t|\n",
      "|Loading: 215 |Mean HR: 678.05 |Len beats: 168\t, labels: 168\t|\n",
      "|Loading: 217 |Mean HR: 445.23 |Len beats: 422\t, labels: 422\t|\n",
      "|Loading: 219 |Mean HR: 447.71 |Len beats: 72\t, labels: 72\t|\n",
      "|Loading: 220 |Mean HR: 412.71 |Len beats: 94\t, labels: 94\t|\n",
      "|Loading: 221 |Mean HR: 509.46 |Len beats: 396\t, labels: 396\t|\n",
      "|Loading: 222 |Mean HR: 526.55 |Len beats: 421\t, labels: 421\t|\n",
      "|Loading: 223 |Mean HR: 538.55 |Len beats: 576\t, labels: 576\t|\n",
      "|Loading: 228 |Mean HR: 447.72 |Len beats: 365\t, labels: 365\t|\n",
      "|Loading: 230 |Mean HR: 450.06 |Len beats: 1\t, labels: 1\t|\n",
      "|Loading: 231 |Mean HR: 314.60 |Len beats: 3\t, labels: 3\t|\n",
      "|Loading: 232 |Mean HR: 425.15 |Len beats: 1383\t, labels: 1383\t|\n",
      "|Loading: 233 |Mean HR: 680.89 |Len beats: 849\t, labels: 849\t|\n",
      "|Loading: 234 |Mean HR: 549.05 |Len beats: 53\t, labels: 53\t|\n",
      "|Total records: 1\n",
      "|Classes: {4}\n",
      "|Loading: 100 |Mean HR: 454.73 |Len beats: 2239\t, labels: 2239\t|\n"
     ]
    }
   ],
   "source": [
    "p = process_data()\n",
    "# records from all sets excluding those in class N\n",
    "p.create_img_arrays(supergroups_exc_n, record_names)\n",
    "# records from the first set with only those in class N\n",
    "p.create_img_arrays(supergroups_inc_n, record_names[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1a78a66f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (14190, 281, 362, 1)\n",
      "Labels: (14190,)\n"
     ]
    }
   ],
   "source": [
    "label_strings = p.label_strings\n",
    "image_arrays = p.image_arrays\n",
    "print(f\"Images: {image_arrays.shape}\\nLabels: {label_strings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "517f258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "np.save(f'{file_name}_data_reduced', p.image_arrays)\n",
    "np.save(f'{file_name}_labels_reduced', p.label_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4dcaccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  Class   |  Count   |\n",
      "|---------------------|\n",
      "|    0     |   2983   |\n",
      "|    1     |   7165   |\n",
      "|    2     |   1774   |\n",
      "|    3     |    32    |\n",
      "|    4     |   2236   |\n",
      "|---------------------|\n",
      "|Total        14190   |\n",
      "|Probability  19.95%  |\n"
     ]
    }
   ],
   "source": [
    "# calculate the probability of using simple random guesses\n",
    "# this is used as the baseline for statistical significance\n",
    "\n",
    "count = 0\n",
    "class_counts = np.histogram(label_strings, bins=(0,1,2,3,4,5))\n",
    "counts = np.append(class_counts[-1][:-1].tolist(), class_counts[0])\n",
    "counts = np.transpose(counts.reshape((2, 5)), axes=None)\n",
    "\n",
    "t1 = f\"Class\"\n",
    "t2 = f\"Count\"\n",
    "line = \"|---------------------|\"\n",
    "print(f\"|{t1:^10}|{t2:^10}|\")\n",
    "print(line)\n",
    "\n",
    "for pair in counts:\n",
    "    output = f\"|{pair[0]: ^10}|{pair[1]:^10}|\"\n",
    "    print(output)\n",
    "\n",
    "print(line)\n",
    "print(f\"|Total{len(label_strings): >13}   |\")\n",
    "\n",
    "for label in label_strings:\n",
    "    if np.random.randint(5) == label:\n",
    "        count += 1\n",
    "    \n",
    "prob = (count / len(label_strings)) * 100\n",
    "print(f\"|Probability {prob: >6.2f}%  |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfdb.io.show_ann_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b1b78",
   "metadata": {},
   "source": [
    "## Supergroups [cite]\n",
    "\n",
    "### Normal\n",
    "- **Normal beat (N)**\n",
    "\n",
    "### Supraventricular\n",
    "- **Atrial premature beat (A)**\n",
    "- **Aberrated atrial premature beat (a)**\n",
    "- **Nodal (junctional) premature beat (J)**\n",
    "- **Supraventricular premature or ectopic beat (S)**\n",
    "- **Atrial escape beat (e)**\n",
    "- **Nodal (junctional) escape beat (j)**\n",
    "- **Supraventricular escape beat (n)**\n",
    "\n",
    "### Ventricular\n",
    "- **Premature ventricular contraction (V)**\n",
    "- **R-on-T premature ventricular contraction (r)**\n",
    "- **Ventricular escape beat (E)**\n",
    "\n",
    "### Fusion\n",
    "- **Fusion of ventricular and normal beat (F)**\n",
    "- **Fusion of paced and normal beat (f)**\n",
    "\n",
    "### Unknown\n",
    "- **Unclassifiable beat (Q)**\n",
    "- **Beat not classified during learning (learning) (?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a39d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
