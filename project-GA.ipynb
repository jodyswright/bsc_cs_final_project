{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc53597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# pip install tensorflow Version: 2.17.0\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras import models, layers\n",
    "\n",
    "# Version: 3.4.1\n",
    "from tensorflow import keras\n",
    "\n",
    "# use for splitting the test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from scipy import spatial\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for the creation of the cartesian product grid\n",
    "from itertools import product\n",
    "\n",
    "# for the timing of each test\n",
    "import time\n",
    "\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "# the data tools module\n",
    "import data_tools as dt\n",
    "dh = dt.Data_Handling(output_size=5)\n",
    "\n",
    "# set the paths to used by physionet\n",
    "label_path = 'mitdb_labels_reduced.npy'\n",
    "data_path = 'mitdb_data_reduced.npy'\n",
    "\n",
    "# get the data\n",
    "dh.load_data(label_path=label_path, data_path=data_path)\n",
    "\n",
    "# split into train and test sets\n",
    "dh.split_data(split=0.2)\n",
    "\n",
    "print(dh.X_train.shape, dh.X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38f9d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population:\n",
    "    '''\n",
    "    Class to create a population of genomes with each containing genes of random float values\n",
    "    \n",
    "    attributes:\n",
    "        layer_size\n",
    "        layer_shape\n",
    "    '''\n",
    "    def __init__(self, max_layers=5, global_len=3, layer_len=3, dp=4):\n",
    "        self.__max_layers = max_layers\n",
    "        self.__global_len = global_len\n",
    "        self.__layer_len = layer_len\n",
    "        self.__layer_shape = None\n",
    "        self.__dp = dp\n",
    "\n",
    "#     @property\n",
    "#     def global_size(self):\n",
    "#         return self.__global_size\n",
    "    \n",
    "    @property\n",
    "    def layer_size(self):\n",
    "        return self.__layer_size\n",
    "    \n",
    "    @property\n",
    "    def layer_shape(self):\n",
    "        return self.__layer_shape\n",
    "    \n",
    "    @property\n",
    "    def max_layers(self):\n",
    "        return self.__max_layers\n",
    "    \n",
    "    def get_genome(self, layers=1):\n",
    "        '''\n",
    "        Creates a genome to include a global gene and at least 1 layer\n",
    "        \n",
    "        Params:\n",
    "            size (int) the number of layers within the genome\n",
    "            dp (int) the number of decimal places for each value in the genes\n",
    "        Returns:\n",
    "            (np.array) a set of genes\n",
    "        '''\n",
    "        assert layers >= 1, \"Size must be at least 1\"\n",
    "\n",
    "        # golbal gene\n",
    "#         genome = list(self.get_gene(size=self.__global_len))\n",
    "        genome = self.get_gene(size=self.__global_len)\n",
    "        # layers from random genes\n",
    "        layers = [self.get_gene(size=self.__layer_len) for gene in range(layers)]\n",
    "        genome.extend(layers)\n",
    "        \n",
    "        return genome\n",
    "    \n",
    "    \n",
    "    def get_gene(self, size=4):\n",
    "        '''\n",
    "        Creates gene of the given size with a set number of decimal places\n",
    "        \n",
    "        Params:\n",
    "            size (int) the number of values within the gene\n",
    "            dp (int) the number of decimal places for each value in the gene\n",
    "        \n",
    "        Returns:\n",
    "            (np.array) a single gene\n",
    "        '''\n",
    "        \n",
    "#         set in powers of 10 to control the decimal places\n",
    "        ubound = 10 ** self.__dp\n",
    "#         create a random gene of the given size\n",
    "        gene = np.random.randint(0, ubound,  size=size)/ubound\n",
    "#         pad with -1s to max size to create uniform size\n",
    "\n",
    "        return list(gene)\n",
    "    \n",
    "    def get_population(self, pop_size=3):\n",
    "        '''\n",
    "        Creates a population of the given size with random length genomes\n",
    "        \n",
    "        Params:\n",
    "            pop_size (int) the number random genomes to return\n",
    "        \n",
    "        Returns:\n",
    "            (np.array) a set of genomes\n",
    "        '''\n",
    "        population = []\n",
    "        for i in range(pop_size):\n",
    "            \n",
    "            layers = np.random.randint(1, self.__max_layers + 1)\n",
    "            population.append(self.get_genome(layers=layers))\n",
    "\n",
    "        return population\n",
    "\n",
    "pn = Population(max_layers=4, global_len=mc.global_len, layer_len=mc.layer_len, dp=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1616fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pn.get_population(3)\n",
    "save_dict(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67466c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Constructor:\n",
    "    '''\n",
    "    handles the stages of mapping a genome to the required set of \n",
    "    hyper-parameter values of various types. these are used to build and\n",
    "    compile a training ready model\n",
    "\n",
    "    parameters\n",
    "        shape (tuple) specifies the input shape of the data to be modelled eg (28, 28, 1) \n",
    "        output_size (int) the number of classes to be modelled eg 5\n",
    "        \n",
    "    attributes:\n",
    "        gene_spec: the specification for each genome\n",
    "        layer_len: the length of the current layer config gene\n",
    "        global_len: the length of the global parameter gene\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, shape, output_size):\n",
    "        \n",
    "        self.set_gene_spec()\n",
    "#         self.__layer_len = None\n",
    "#         self.__global_len = None\n",
    "        self.__shape = shape\n",
    "        self.__output_size = output_size\n",
    "        \n",
    "    def set_gene_spec(self):\n",
    "        '''\n",
    "        sets up the genespec for use with the model constructor \n",
    "        gene values are mapped to the ranges specifiec using the map_params function\n",
    "        '''\n",
    "        start_sizes = [i for i in range(8, 33, 8)]\n",
    "        dropout_rates = [i/10 for i in range(2, 6, 1)]\n",
    "        filters = [i/10 for i in range(11, 20)]\n",
    "        binary = [True, False]\n",
    "        batch_sizes = [v for v in range(64, 256, 32)]\n",
    "        \n",
    "        self.__gene_spec = {\n",
    "            'global':{\n",
    "                'learning_rate':[0.1, 0.01, 0.001, 0.0001],\n",
    "                'optimizer':['adam', 'sgd'],\n",
    "                'start_size':start_sizes,\n",
    "                'batch_size':batch_sizes,\n",
    "            },\n",
    "            'layer':{\n",
    "    \n",
    "                    'filter_size':filters,\n",
    "                    'filter_activation': ['relu'],\n",
    "                    'dropout_exists': binary,\n",
    "                    'dropout_rate': dropout_rates,\n",
    "                    'max_pool_exists': binary,\n",
    "                    'max_pool_size' : [2, 3]\n",
    "            }   \n",
    "        }\n",
    "        # set the parameter lengths which in the case of the layers is a single layer length\n",
    "        self.__layer_len = len(self.__gene_spec['layer'])\n",
    "        self.__global_len = len(self.__gene_spec['global']) \n",
    "        \n",
    "    @property\n",
    "    def gene_spec(self):\n",
    "        return self.__gene_spec\n",
    "    \n",
    "    @property\n",
    "    def layer_len(self):\n",
    "        return self.__layer_len\n",
    "    \n",
    "    @property\n",
    "    def global_len(self):\n",
    "        return self.__global_len\n",
    "         \n",
    "    def map_params(self, gene_spec, gene):\n",
    "        '''\n",
    "        maps a gene's values to the corresponding range in the gene_spec\n",
    "        \n",
    "        parameters:\n",
    "            gene_spec (dict) a subsection of the genespec eg global or layer\n",
    "            gene (array float) set of numbers used to map to the spec's ranges\n",
    "        \n",
    "        returns:\n",
    "            (dict) the parameters mapped to the gene\n",
    "        '''\n",
    "        params = {}\n",
    "        for i, key in enumerate(gene_spec.keys()):\n",
    "            idx = math.floor(len(gene_spec[key]) * gene[i])\n",
    "            params[key] = gene_spec[key][idx]\n",
    "\n",
    "        return params\n",
    "    \n",
    "    def get_param_dict(self, genome):\n",
    "        '''\n",
    "        creates a dictionary containing the useable parameters for the model components\n",
    "        \n",
    "        parameters:\n",
    "            genome (2d array float) containing genes to construct a model\n",
    "        \n",
    "        returns:\n",
    "            (dict) the mapped global parameters\n",
    "            (dict) the mapped local parameters\n",
    "        \n",
    "        '''\n",
    "        # split the golbals and map to dict\n",
    "        spec = self.__gene_spec['global'].copy()\n",
    "        gene = genome[:self.__global_len]\n",
    "        global_params = self.map_params(spec, gene)\n",
    "\n",
    "        # split out the layer genes and loop over to map\n",
    "        layer_params = {}\n",
    "        spec = self.__gene_spec['layer'].copy()\n",
    "        gnm = genome[self.__global_len:]\n",
    "\n",
    "        for i, gene in enumerate(gnm):\n",
    "            layer_params[f'layer_{i}'] = self.map_params(spec, gene)\n",
    "            \n",
    "        return global_params, layer_params\n",
    "    \n",
    "    def build_model(self, global_params, layer_params):\n",
    "        '''\n",
    "        builds a keras model of varying depth.\n",
    "        the depth is defined by the length of the layer_params\n",
    "        layers such as dropout and pooling are added if the parameters specifies true\n",
    "        each layer will have at least 1 conv2d and at most conv2d, maxpool, dropout\n",
    "        parameters are defined by the two sets passed in\n",
    "        \n",
    "        parameters:\n",
    "            global_params (dict) parameters common to the model as a whole\n",
    "            layer_params (dict) parameters specific to the hidden layers\n",
    "            \n",
    "        returns:\n",
    "            (keras.model) a compliled model ready for training\n",
    "        \n",
    "        '''\n",
    "        # used for the scaling of each filter size\n",
    "        prev_size = global_params['start_size']\n",
    "        # new empty model\n",
    "        model = keras.Sequential()\n",
    "    #     # set the input shape\n",
    "        model.add(keras.Input(shape=self.__shape))\n",
    "        \n",
    "        for i, key in enumerate(layer_params.keys()):\n",
    "            # extract the current layer's parameters to make code more readable\n",
    "            params = layer_params[key]\n",
    "            # calculate the layer size base on the previous size\n",
    "            layer_size = int(params['filter_size'] * prev_size)\n",
    "            \n",
    "            # CONV2D\n",
    "            model.add(\n",
    "                keras.layers.Conv2D(\n",
    "                    filters=layer_size, \n",
    "                    kernel_size=3, \n",
    "                    activation=params['filter_activation']\n",
    "                )\n",
    "            )\n",
    "            # MAX POOL\n",
    "            model.add(\n",
    "                keras.layers.MaxPooling2D(\n",
    "                    pool_size=params['max_pool_size']\n",
    "                )\n",
    "            )\n",
    "            # DROPOUT\n",
    "            if params['dropout_exists']:\n",
    "                # only add a droput layer if param = true\n",
    "                model.add(\n",
    "                    keras.layers.Dropout(\n",
    "                        rate=params['dropout_rate']\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            prev_size = layer_size\n",
    "            \n",
    "        # OUTPUT\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(self.__output_size, activation=\"softmax\"))      \n",
    "\n",
    "        # compile the model\n",
    "        model.compile(optimizer=global_params['optimizer'],\n",
    "                      loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e834b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model constructor to handle the build and training of each genome\n",
    "mc = Model_Constructor(shape=dh.shape, output_size=5)\n",
    "# new population constructor to create sets of genomes for each successive generation\n",
    "pn = Population(max_layers=4, global_len=mc.global_len, layer_len=mc.layer_len, dp=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec06818",
   "metadata": {},
   "source": [
    "### For the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762de4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop = pn.get_population(pop_size=5)\n",
    "genome = pop[0]\n",
    "pprint.pp(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac81c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_params, layer_params = mc.get_param_dict(genome)\n",
    "pprint.pp(global_params)\n",
    "pprint.pp(layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mc.build_model(global_params, layer_params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14811db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA_Optimizer:\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.__X = X\n",
    "        self.__y = y\n",
    "        \n",
    "    def test_population(self):\n",
    "        pass\n",
    "    \n",
    "    def evolve_the_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02245c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(dict):\n",
    "\n",
    "    file_name = f'{str(datetime.now())[:16]}_ga_results.json'\n",
    "    f = open(file_name, \"w\")\n",
    "\n",
    "    json.dump(dict, f, indent = 6)\n",
    "\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1abf8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_population(population, X, y, max_epochs, validation_split=0.2, callbacks=[], monitor_string=\"\"):\n",
    "    \n",
    "    best_results = []\n",
    "    best_epochs = []\n",
    "    best_so_far = float(\"inf\")\n",
    "    for i, genome in enumerate(population):\n",
    "        # map the gene and build the model\n",
    "        g, l = mc.get_param_dict(genome)\n",
    "        model = mc.build_model(g, l)\n",
    "        # monitor metrics \n",
    "        depth = len(l.keys())\n",
    "        batch_size = g['batch_size']\n",
    "        \n",
    "        # process update to user\n",
    "        clear_output()\n",
    "        print(f'{monitor_string}')\n",
    "        print(f'Testing run: \\t| {i + 1}/{len(population)}')\n",
    "        print(f'Depth:\\t\\t| {depth}')\n",
    "        print(f'Batch size:\\t| {batch_size}\\n')\n",
    "        print(f'Best this gen: {best_so_far}\\n')\n",
    "        \n",
    "        # fit to the data \n",
    "        model.fit( \n",
    "                    X, \n",
    "                    y,\n",
    "                    epochs=max_epochs, \n",
    "                    validation_split=validation_split, \n",
    "                    batch_size=g['batch_size'], \n",
    "                    callbacks=[callbacks],\n",
    "                    verbose=1\n",
    "                )\n",
    "        \n",
    "        # get the training history\n",
    "        hist = model.history.history['val_loss']\n",
    "    #   store best fitness and the best epoch for survival of the fittest\n",
    "        best_result = hist[-1]\n",
    "        # for monitoring during the test\n",
    "        best_so_far = min(best_so_far, best_result)\n",
    "        # for output for use in the Evolution class\n",
    "        best_epochs.append(len(hist))\n",
    "        best_results.append(best_result)\n",
    "        \n",
    "        \n",
    "    return best_results, best_epochs\n",
    "    \n",
    "\n",
    "def evolve_the_model(\n",
    "    X, y, generations, pop_size, start_epochs, epoch_factor, fitness_func):\n",
    "    \n",
    "    # create the callbacks\n",
    "    monitor = 'val_loss'\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(\n",
    "            monitor=monitor, \n",
    "            patience=3,\n",
    "            mode='min'\n",
    "    )]\n",
    "    results = {}\n",
    "    file_path = 'ga_results.json'\n",
    "    \n",
    "    epochs=start_epochs\n",
    "    # for monitoring\n",
    "    best_so_far = float(\"inf\")\n",
    "    # get initial population of size n\n",
    "    pop = pn.get_population(pop_size=pop_size)\n",
    "    # evolve for the number of generations\n",
    "    for generation in range(generations):\n",
    "        \n",
    "        results[generation] = {'population': pop, 'epochs':epochs}\n",
    "#         save_dict(results)\n",
    "        \n",
    "        monitor_string = f'Generation\\t| {generation + 1} of {generations} for {epochs} epochs\\n'\n",
    "        monitor_string += f'Best so far:\\t| {best_so_far}\\n'\n",
    "        \n",
    "        fits, best_epochs = test_population(\n",
    "            population=pop, \n",
    "            X=X, \n",
    "            y=y, \n",
    "            max_epochs=epochs, \n",
    "            validation_split=0.2, \n",
    "            callbacks=callbacks, \n",
    "            monitor_string=monitor_string)\n",
    "        \n",
    "        \n",
    "        fittest = min(fits)\n",
    "        best_so_far = min(best_so_far, fittest)\n",
    "        \n",
    "        results[generation].update({'fits':fits, 'best_epochs':best_epochs})\n",
    "#         save_dict(results)\n",
    "        \n",
    "        epochs = epochs + epoch_factor\n",
    "    # get next pop from the Evolution class of size n\n",
    "    # EDIT THIS TO THE CORRECT POP SOURCE!\n",
    "#         print(f'Next generation')\n",
    "        pop = fitness_func(fits, pop)\n",
    "        \n",
    "    return results\n",
    "    # can also reduce the population using the same idea - try as an experiment\n",
    "    \n",
    "    # also try using the early stopping as a bespoke in that if performance has\n",
    "    # not improved for n generations then end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a140de45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation\t| 1 of 10 for 10 epochs\n",
      "Best so far:\t| inf\n",
      "\n",
      "Testing run: \t| 1/20\n",
      "Depth:\t\t| 3\n",
      "Batch size:\t| 160\n",
      "\n",
      "Best this gen: inf\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m46/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 704ms/step - accuracy: 0.4976 - loss: 16.5573"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m dh\u001b[38;5;241m.\u001b[39mX_train\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m dh\u001b[38;5;241m.\u001b[39my_train\n\u001b[0;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevolve_the_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfitness_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_generation\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 75\u001b[0m, in \u001b[0;36mevolve_the_model\u001b[0;34m(X, y, generations, pop_size, start_epochs, epoch_factor, fitness_func)\u001b[0m\n\u001b[1;32m     72\u001b[0m monitor_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeneration\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m| \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     73\u001b[0m monitor_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest so far:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m| \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_so_far\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 75\u001b[0m fits, best_epochs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_population\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpopulation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonitor_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m fittest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(fits)\n\u001b[1;32m     86\u001b[0m best_so_far \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(best_so_far, fittest)\n",
      "Cell \u001b[0;32mIn[16], line 23\u001b[0m, in \u001b[0;36mtest_population\u001b[0;34m(population, X, y, max_epochs, validation_split, callbacks, monitor_string)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest this gen: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_so_far\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# fit to the data \u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# get the training history\u001b[39;00m\n\u001b[1;32m     34\u001b[0m hist \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = dh.X_train\n",
    "y = dh.y_train\n",
    "\n",
    "results = evolve_the_model(\n",
    "    X=X, y=y, \n",
    "    generations=10, \n",
    "    pop_size=20, \n",
    "    start_epochs=10, \n",
    "    epoch_factor=2, \n",
    "    fitness_func=ev.get_next_generation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f73cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results[1] = {'population':list(pop[0][4])}\n",
    "save_dict(results)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pn.get_population(pop_size=5)\n",
    "\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results, best_epochs = test_population(\n",
    "    population=pop, X=X, y=y, max_epochs=2, validation_split=0.2, callbacks=[], monitor_string=\"Test\"\n",
    ")\n",
    "print(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see twitter bookmark\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "with alive_bar() as bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbaede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild and train on entire set\n",
    "model = mc.build_model(g, l)\n",
    "vaidation_split = 0\n",
    "\n",
    "mc.train_model(\n",
    "    model, \n",
    "    X, \n",
    "    y, \n",
    "    epochs=max_epochs, \n",
    "    split=vaidation_split, \n",
    "    batch=g['batch_size']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d1d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(X, y, batch_size=g['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c184ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fba30b",
   "metadata": {},
   "source": [
    "### Repeatability\n",
    "- The default initializer is random_glorot with a default seed=None.   \n",
    "- This, according to keras, produces a deterministic set of values https://keras.io/api/layers/initializers/  \n",
    "- \"Note that an initializer seeded with an integer or None (unseeded) will produce the same random values across multiple calls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737bc032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evolution:\n",
    "    '''\n",
    "    Requires the Genome class using the static functions - instance not required\n",
    "    \n",
    "    Params:\n",
    "            probability (float) the rate of probability eg 1 is 100% and 0.5 is 50%\n",
    "            highest_is_fittest (bool) if true then higher values are considered fitter (eg accuracy)\n",
    "                          if false thenlower values are considered fitter (eg loss)\n",
    "            aggression (float) a higher number gives more weight to the fitter values giving a higher\n",
    "                                probability of these being chosen in the selection function\n",
    "            global_len (int) the length of the global gene in which each paramter represented by a single value\n",
    "            mutation_amount (float [0.0, 0.1]) the amount of mutation to be applied to any gene value \n",
    "    '''\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        probability=0.1,\n",
    "        highest_is_fittest=True, \n",
    "        aggression=2,\n",
    "        global_len=4,  \n",
    "        mutation_amount=0.01,\n",
    "        max_depth=5\n",
    "    ):\n",
    "        self.__probability = probability\n",
    "        self.__highest_is_fittest = highest_is_fittest \n",
    "        self.__aggression = aggression\n",
    "        self.__global_len = global_len \n",
    "        self.__mutation_amount = mutation_amount\n",
    "        self.__max_depth = max_depth\n",
    "\n",
    "    def probability_test(self):\n",
    "        '''\n",
    "        Returns true if the random number is below that of the rate parameter\n",
    "        This gives a probabilty test for any defined operations\n",
    "        \n",
    "        Returns:\n",
    "            (bool) true if the random number is less than the rate parameter\n",
    "        '''\n",
    "        return True if np.random.rand() < self.__probability else False\n",
    "\n",
    "    def select_fittest(self, fits):\n",
    "        '''\n",
    "        selects the fittest value from a list using the roulette method and returns \n",
    "        the index value of the original source list which can then be applied to a \n",
    "        list of genes or parameters if build using the same order\n",
    "        \n",
    "        parameters:\n",
    "            fits (array float) fitness values for a set of models\n",
    "\n",
    "        returns:\n",
    "            (int) the index value of the fittest value in the list\n",
    "        '''\n",
    "        # arbitary figure to ensure all significant values are integers\n",
    "        int_scale = 10000\n",
    "        \n",
    "        if self.__highest_is_fittest:\n",
    "            fits = (np.array(fits) * int_scale).astype(int)\n",
    "        else:\n",
    "#           invert the values in order to prioritize the lowest\n",
    "            fits = (1 /np.array(fits) * int_scale).astype(int)\n",
    "        # order the values such that the larger have a wider interval\n",
    "        cum_array = (np.cumsum(np.sort(fits)) * self.__aggression).astype(int)\n",
    "        # choose random int between zero and max of the cum array scaled by the exponent 1/aggression\n",
    "        random_idx = int((np.random.rand() ** (1/self.__aggression)) * cum_array[-1])\n",
    "#         find the corresponding index value within the cum array\n",
    "        idx = np.searchsorted(cum_array, random_idx, side=\"left\")\n",
    "\n",
    "        # Get the sorted indices of the array\n",
    "        sorted_indices = np.argsort(fits)\n",
    "    #     extrapolate back the index to that of the corresponding value in the fits array\n",
    "        res = sorted_indices[idx]\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def point_mutate(self, genome):\n",
    "        '''\n",
    "        Randomly mutates a gene or genes within the given set of genes. \n",
    "        The gene values are either increased or decreased depending on the random number -0.5 to 0.5. \n",
    "\n",
    "        Params:\n",
    "            genome (np.array) the set of genes to be mutated\n",
    "\n",
    "        Returns:\n",
    "            (list) the mutated set of genes\n",
    "        '''\n",
    "\n",
    "        for i, element in enumerate(genome):\n",
    "            # only layer genes will have the __len__ attribute\n",
    "            if hasattr(element, \"__len__\"):\n",
    "                # sub divide any genes into individual scalars and mutate\n",
    "                for j, sub_element in enumerate(element):\n",
    "                    genome[i][j] = self.mutate_gene_value(sub_element)\n",
    "            else:\n",
    "            # others will be scalar global gene values\n",
    "                genome[i] = self.mutate_gene_value(element)\n",
    "            \n",
    "        return genome\n",
    "    \n",
    "    def mutate_gene_value(self, gene_value):\n",
    "        \n",
    "        if self.probability_test():\n",
    "            \n",
    "            mutation = (np.random.rand() - 0.5) * self.__mutation_amount\n",
    "            gene_value = gene_value + mutation\n",
    "            # fix value in the interval [0.0, 1.0] \n",
    "            gene_value = min(max(gene_value, 0), 1)\n",
    "            \n",
    "        return gene_value\n",
    "    \n",
    "    def shrink_mutate(self, genome):\n",
    "        '''\n",
    "        Probabilistically removes one gene to the genes set resulting in one less layer\n",
    "        \n",
    "        Params:\n",
    "            genome (np.array) set of genes to be mutated\n",
    "            \n",
    "        Returns:\n",
    "            (np.array) set of genes with len genes or genes - 1\n",
    "        '''\n",
    "        min_depth = 2\n",
    "#         ensure that the deep layer count is always >= 1\n",
    "\n",
    "        depth = self.get_genome_depth(genome)\n",
    "\n",
    "        if depth <= min_depth: return genome\n",
    "\n",
    "        if self.probability_test():\n",
    "            idx = np.random.randint(1, depth)\n",
    "            genome = genome[:-idx]\n",
    "\n",
    "        return genome\n",
    "    \n",
    "    def grow_mutate(self, genome):\n",
    "        '''\n",
    "        Probabilistically adds one gene to the genes set, resulting in another layer\n",
    "        \n",
    "        Params:\n",
    "            genome (np.array) set of genes to be mutated\n",
    "            \n",
    "        Returns:\n",
    "            (np.array) set of genes with len genes or genes + 1\n",
    "        '''\n",
    "        new_genome = []\n",
    "        layer_width = len(genome[-1])\n",
    "        depth = self.get_genome_depth(genome)\n",
    "        \n",
    "#       ensure layers never exceeds the maximum number of layers\n",
    "#       split at the global params index to get layers len\n",
    "        if depth >= self.__max_depth:\n",
    "               return genome\n",
    "\n",
    "        if self.probability_test():\n",
    "        # adds a new layer but not exceeding the max layers\n",
    "            new_gene = pn.get_gene(size=layer_width)\n",
    "            genome = genome + list([new_gene])\n",
    "                \n",
    "        return genome\n",
    "    \n",
    "    def crossover(self, genome_1, genome_2):\n",
    "        '''\n",
    "        Merges two genes at a random point to create a new \"child\" gene\n",
    "        \n",
    "        Params:\n",
    "            gene1 (np.array) single gene\n",
    "            gene2 (np.array) single gene\n",
    "            \n",
    "        Returns:\n",
    "            (np.array) set of genes with len genes or genes + 1\n",
    "        '''\n",
    "#         use min() to ensure the index remains in the bounds \n",
    "#         of the smaller gene array\n",
    "        idx = random.randint(\n",
    "            0, min(len(genome_1), len(genome_2))\n",
    "        )\n",
    "\n",
    "        child = genome_1[:idx].copy()\n",
    "        child.extend(genome_2[idx:].copy())\n",
    "        \n",
    "        return child\n",
    "    \n",
    "    def get_genome_depth(self, genome):\n",
    "        return len(genome[self.__global_len:])\n",
    "    \n",
    "    def get_next_generation(self, fits, pop):\n",
    "        '''\n",
    "        create a population of the size defined in the class parameters\n",
    "        \n",
    "        parameters:\n",
    "            fits (array) set of floats taken from each models evaluation performance\n",
    "            pop (2d array) the current population under evaluation\n",
    "        '''\n",
    "        next_generation = []\n",
    "        for i in range(len(fits)):\n",
    "#             find the index two fit parents\n",
    "            p1 = self.select_fittest(fits)\n",
    "            p2 = self.select_fittest(fits)\n",
    "        \n",
    "#             get the genome of each parent\n",
    "            gn1 = pop[p1]\n",
    "            gn2 = pop[p2]\n",
    "            \n",
    "#             mate the parents\n",
    "            child = self.crossover(gn1, gn2)\n",
    "    \n",
    "#             apply the point mutation to the child\n",
    "            child = self.point_mutate(child.copy())\n",
    "#             grow, shrink or retain the depth using the probability applied within the functions\n",
    "            size_mutate = {\n",
    "                1: self.grow_mutate(child),\n",
    "                2: self.shrink_mutate(child),\n",
    "                3: child}\n",
    "            p = np.random.randint(1, 4)\n",
    "            child = size_mutate[p]\n",
    "            \n",
    "            next_generation.append(child)\n",
    "            \n",
    "        return next_generation\n",
    "    \n",
    "ev = Evolution(probability=0.1,highest_is_fittest=False, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0693183",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = [0.5,0.3,1,0.6,0.1]\n",
    "next_gen = ev.get_next_generation(fits, pop)\n",
    "print(f'Pop size: {[len(g) for g in pop]}')\n",
    "print(f'Next gen: {[len(g) for g in next_gen]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "child = ev.crossover(pop[0].copy(), pop[1].copy())\n",
    "child\n",
    "# ev.point_mutate(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a971c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a9bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "child = []\n",
    "c1 = pop[0][:idx].copy()\n",
    "c2 = pop[1][idx:].copy()\n",
    "print(f'{c1}\\n{c2}')\n",
    "\n",
    "child.extend(c1)\n",
    "child.extend(c2)\n",
    "print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# fits = [30, 20,10,10000,500,600,700,0.1]\n",
    "# fits = [0.4,0.3,0.6,0.1,0.7,0.2,0.18,0.1]\n",
    "fits = [1,2,3,4,5]\n",
    "# fits = best_results\n",
    "results = []\n",
    "pop = pn.get_population(pop_size=20)\n",
    "for i in range(1000):\n",
    "    res = ev.select_fittest(fits)\n",
    "    results.append(fits[res])\n",
    "    \n",
    "unique, counts = np.unique(results, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe89e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ev.select_fittest(best_results)\n",
    "print(best_results, best_results[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop = pn.get_population(pop_size=5)\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cedd06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop_test = pn.get_population(pop_size=10)\n",
    "c1 = pop_test[0]\n",
    "c2 = pop_test[1]\n",
    "print(f'C1{c1}\\n\\nC2{c2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d63ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c0, idx = ev.crossover(c1, c2)\n",
    "print(f'idx: {idx}\\n\\nC0{c0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mutated_genome = ev.grow_mutate(c1)\n",
    "mutated_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38cde4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutated_genome = ev.shrink_mutate(c1)\n",
    "mutated_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = c1.copy()\n",
    "mutated_genome = ev.point_mutate(genome)\n",
    "mutated_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ffc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use in the model builder to assign a default in the case of a missing parameter\n",
    "d = {'test':100}\n",
    "d.get('t', 'default')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2be6f0",
   "metadata": {},
   "source": [
    "# Redundant Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f77848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# class Model_Handler:\n",
    "    \n",
    "#     def __init__(self, shape, output_size, global_size, layer_size):\n",
    "#         self.__shape = shape\n",
    "#         self.__output_size = output_size\n",
    "#         # the size of the global parameters eg global_params = params[:global_size]\n",
    "#         self.__global_size = global_size\n",
    "#         # the size of each layer's parameters eg n arrays of width layer_size\n",
    "#         self.__layer_size = layer_size\n",
    "\n",
    "# #     def build_model(self, global_params, layer_params):\n",
    "        \n",
    "# #         # used for the scaling of each filter size\n",
    "# #         prev_size = global_params[2]\n",
    "# #         # new empty model\n",
    "# #         model = keras.Sequential()\n",
    "# #         # set the input shape\n",
    "# #         model.add(keras.Input(shape=self.__shape))\n",
    "# #         # using a reshaped layer parameter array loop each and apply\n",
    "# #         for size_scale, dropout, rate in layer_params:\n",
    "# #             layer_size = int(size_scale * prev_size)\n",
    "# #             # set the layer size as a multiple of the previous using the size_scale param\n",
    "# #             model.add(keras.layers.Conv2D(filters=layer_size, kernel_size=3, activation=\"relu\"))\n",
    "# #             model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "# #             # only add a droput layer if param = true\n",
    "# #             if dropout:\n",
    "# #                 model.add(keras.layers.Dropout(rate=rate))\n",
    "\n",
    "# #             prev_size = layer_size\n",
    "\n",
    "# #         # add the final layers of the model\n",
    "# #         model.add(keras.layers.Flatten())\n",
    "# #         model.add(keras.layers.Dense(self.__output_size, activation=\"softmax\"))      \n",
    "\n",
    "# #         # compile the model\n",
    "# #         model.compile(optimizer=\"rmsprop\",\n",
    "# #                       loss=\"sparse_categorical_crossentropy\",\n",
    "# #                       metrics=[\"accuracy\"])\n",
    "\n",
    "# #         return model\n",
    "    \n",
    "#     def train_model(model, X, y, epochs, split, batch, callbacks):\n",
    "#         model.fit(\n",
    "#         dh.X_train[:1000], \n",
    "#         dh.y_train[:1000], \n",
    "#         epochs=max_epochs, \n",
    "#         validation_split=val_split, \n",
    "#         batch_size=batch_size, \n",
    "#         callbacks=[callbacks]\n",
    "#     )\n",
    "        \n",
    "#     def test_population(self, population):\n",
    "#         # split into global and layer params\n",
    "#         global_params = params[:self.__global_size]\n",
    "#         layer_params = np.array(params[self.__global_size:]).reshape(self.__layer_shape)\n",
    "        \n",
    "#         for genome in population:\n",
    "#             print(genome)\n",
    "# #             model = self.build_model(global_params, layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e9545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# mh = Model_Handler(\n",
    "#     shape=(281, 362, 1), \n",
    "#     output_size=5, \n",
    "#     global_size=population.global_size, \n",
    "#     layer_shape=population.layer_shape\n",
    "# )\n",
    "# # model = mh.build_model(global_params, layer_params)\n",
    "# # model.summary()\n",
    "\n",
    "# mh.test_population(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# # set the params\n",
    "# max_epochs = 5\n",
    "# vaidation_split = 0.2\n",
    "# batch_size = 256\n",
    "\n",
    "# # create the callbacks\n",
    "# monitor = 'val_loss'\n",
    "# checkpoint_path = 'checkpoint_path.keras'\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(\n",
    "#         monitor=monitor, \n",
    "#         patience=3\n",
    "#     ),\n",
    "    \n",
    "# #     keras.callbacks.ModelCheckpoint(\n",
    "# #         filepath=checkpoint_path, \n",
    "# #         monitor=monitor, \n",
    "# #         save_best_only=True\n",
    "# #     )\n",
    "# ]\n",
    "\n",
    "# model.fit(\n",
    "#     dh.X_train[:1000], \n",
    "#     dh.y_train[:1000], \n",
    "#     epochs=max_epochs, \n",
    "#     validation_split=vaidation_split, \n",
    "#     batch_size=batch_size, \n",
    "#     callbacks=[callbacks]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant\n",
    "# initializer = keras.initializers.Ones()\n",
    "# layer = keras.layers.Conv2D(filters=layer_size, kernel_size=3, activation=\"relu\", kernel_initializer=initializer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "ml3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
